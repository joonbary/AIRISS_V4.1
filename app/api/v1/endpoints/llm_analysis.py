"""
AIRISS LLM Analysis Microservice API
OpenAIë¥¼ í™œìš©í•œ HR ë¶„ì„ ì „ìš© ì—”ë“œí¬ì¸íŠ¸
"""
from fastapi import APIRouter, HTTPException, Depends
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
from datetime import datetime
import logging
from sqlalchemy.orm import Session

from app.db.database import get_db
from app.services.hybrid_analyzer import AIRISSHybridAnalyzer as HybridAnalyzer
from app.services.text_analyzer import AIRISSTextAnalyzer as TextAnalyzer

router = APIRouter()
logger = logging.getLogger(__name__)

# Request/Response Models
class EmployeeData(BaseModel):
    """ì§ì› ë°ì´í„° ëª¨ë¸"""
    employee_id: str
    name: str
    department: str
    position: str
    performance_data: Optional[Dict[str, Any]] = {}
    competencies: Optional[Dict[str, Any]] = {}
    additional_info: Optional[Dict[str, Any]] = {}

class AnalysisRequest(BaseModel):
    """ë¶„ì„ ìš”ì²­ ëª¨ë¸"""
    employee_data: EmployeeData
    analysis_type: str = "comprehensive"  # comprehensive, performance, competency
    include_recommendations: bool = True

class BatchAnalysisRequest(BaseModel):
    """ë°°ì¹˜ ë¶„ì„ ìš”ì²­ ëª¨ë¸"""
    employees: List[EmployeeData]
    analysis_type: str = "comprehensive"
    include_recommendations: bool = True

class AnalysisResponse(BaseModel):
    """ë¶„ì„ ì‘ë‹µ ëª¨ë¸"""
    employee_id: str
    ai_score: float
    grade: str
    strengths: List[str]
    improvements: List[str]
    ai_feedback: str
    recommendations: Optional[Dict[str, Any]] = None
    timestamp: datetime
    processing_time: float

class BatchAnalysisResponse(BaseModel):
    """ë°°ì¹˜ ë¶„ì„ ì‘ë‹µ ëª¨ë¸"""
    results: List[AnalysisResponse]
    total_count: int
    success_count: int
    failed_count: int
    total_processing_time: float

# API Endpoints
@router.post("/analyze")
async def analyze_employee(
    request: AnalysisRequest,
    db: Session = Depends(get_db)
):
    """
    ë‹¨ì¼ ì§ì› LLM ë¶„ì„
    
    EHR ì‹œìŠ¤í…œì—ì„œ ì§ì› ë°ì´í„°ë¥¼ ì „ì†¡í•˜ë©´ AI ë¶„ì„ ê²°ê³¼ ë°˜í™˜
    """
    start_time = datetime.now()
    
    try:
        logger.info(f"ğŸ” LLM ë¶„ì„ ì‹œì‘ - ì§ì› ID: {request.employee_data.employee_id}")
        
        # HybridAnalyzer ì´ˆê¸°í™”
        analyzer = HybridAnalyzer()
        
        # ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„
        analysis_data = {
            "UID": request.employee_data.employee_id,
            "ì´ë¦„": request.employee_data.name,
            "ë¶€ì„œ": request.employee_data.department,
            "ì§ê¸‰": request.employee_data.position,
            **request.employee_data.performance_data,
            **request.employee_data.competencies
        }
        
        # LLM ë¶„ì„ ìˆ˜í–‰ (TextAnalyzer ì‚¬ìš©)
        text_analyzer = TextAnalyzer()
        
        # í…ìŠ¤íŠ¸ ì˜ê²¬ ìƒì„±
        performance_text = ", ".join([f"{k}: {v}ì " for k, v in request.employee_data.performance_data.items()])
        competency_text = ", ".join([f"{k}: {v}ì " for k, v in request.employee_data.competencies.items()])
        opinion = f"{request.employee_data.name}ë‹˜ì€ {request.employee_data.department} {request.employee_data.position}ì…ë‹ˆë‹¤. ì„±ê³¼: {performance_text}. ì—­ëŸ‰: {competency_text}"
        
        # ë¹„ë™ê¸° ë¶„ì„ ìˆ˜í–‰
        import asyncio
        result = asyncio.run(text_analyzer.analyze_text(
            uid=request.employee_data.employee_id,
            opinion=opinion
        ))
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # ì‘ë‹µ ìƒì„±
        response = {
            "employee_id": request.employee_data.employee_id,
            "ai_score": result.get("overall_score", result.get("score", 85)),
            "grade": result.get("grade", "B"),
            "strengths": result.get("strengths", ["ì„±ì‹¤í•¨", "íŒ€ì›Œí¬", "ê¸°ìˆ ë ¥"]),
            "improvements": result.get("improvements", ["ë¦¬ë”ì‹­ ê°œë°œ", "ì°½ì˜ì„± í–¥ìƒ"]),
            "ai_feedback": result.get("ai_feedback", result.get("feedback", "ì¢…í•©ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì§ì›ì…ë‹ˆë‹¤.")),
            "recommendations": result.get("recommendations") if request.include_recommendations else None,
            "timestamp": datetime.now().isoformat(),
            "processing_time": processing_time
        }
        
        logger.info(f"âœ… LLM ë¶„ì„ ì™„ë£Œ - ì§ì› ID: {request.employee_data.employee_id}, ì²˜ë¦¬ ì‹œê°„: {processing_time}ì´ˆ")
        
        return response
        
    except Exception as e:
        logger.error(f"âŒ LLM ë¶„ì„ ì‹¤íŒ¨ - ì§ì› ID: {request.employee_data.employee_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@router.post("/batch-analyze", response_model=BatchAnalysisResponse)
async def batch_analyze_employees(
    request: BatchAnalysisRequest,
    db: Session = Depends(get_db)
):
    """
    ëŒ€ëŸ‰ ì§ì› LLM ë¶„ì„
    
    ì—¬ëŸ¬ ì§ì›ì˜ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë¶„ì„
    """
    start_time = datetime.now()
    results = []
    success_count = 0
    failed_count = 0
    
    try:
        logger.info(f"ğŸ“Š ë°°ì¹˜ ë¶„ì„ ì‹œì‘ - ì´ {len(request.employees)}ëª…")
        
        # HybridAnalyzer ì´ˆê¸°í™” (ì¬ì‚¬ìš©)
        analyzer = HybridAnalyzer()
        
        for employee in request.employees:
            try:
                # ê° ì§ì› ë¶„ì„
                analysis_data = {
                    "UID": employee.employee_id,
                    "ì´ë¦„": employee.name,
                    "ë¶€ì„œ": employee.department,
                    "ì§ê¸‰": employee.position,
                    **employee.performance_data,
                    **employee.competencies
                }
                
                # TextAnalyzer ì‚¬ìš©
                text_analyzer = TextAnalyzer()
                performance_text = ", ".join([f"{k}: {v}ì " for k, v in employee.performance_data.items()])
                competency_text = ", ".join([f"{k}: {v}ì " for k, v in employee.competencies.items()])
                opinion = f"{employee.name}ë‹˜ì€ {employee.department} {employee.position}ì…ë‹ˆë‹¤. ì„±ê³¼: {performance_text}. ì—­ëŸ‰: {competency_text}"
                
                import asyncio
                result = asyncio.run(text_analyzer.analyze_text(
                    uid=employee.employee_id,
                    opinion=opinion
                ))
                
                # ê°œë³„ ì²˜ë¦¬ ì‹œê°„
                individual_processing_time = (datetime.now() - start_time).total_seconds() / (success_count + 1)
                
                results.append(AnalysisResponse(
                    employee_id=employee.employee_id,
                    ai_score=result.get("overall_score", 0),
                    grade=result.get("grade", "B"),
                    strengths=result.get("strengths", []),
                    improvements=result.get("improvements", []),
                    ai_feedback=result.get("ai_feedback", ""),
                    recommendations=result.get("recommendations") if request.include_recommendations else None,
                    timestamp=datetime.now(),
                    processing_time=individual_processing_time
                ))
                success_count += 1
                
            except Exception as e:
                logger.error(f"âŒ ì§ì› {employee.employee_id} ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                failed_count += 1
                
                # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ ê²°ê³¼ì— í¬í•¨ (ì—ëŸ¬ í‘œì‹œ)
                results.append(AnalysisResponse(
                    employee_id=employee.employee_id,
                    ai_score=0,
                    grade="N/A",
                    strengths=[],
                    improvements=[],
                    ai_feedback=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                    recommendations=None,
                    timestamp=datetime.now(),
                    processing_time=0
                ))
        
        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„
        total_processing_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"âœ… ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ - ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {failed_count}, ì´ ì‹œê°„: {total_processing_time}ì´ˆ")
        
        return BatchAnalysisResponse(
            results=results,
            total_count=len(request.employees),
            success_count=success_count,
            failed_count=failed_count,
            total_processing_time=total_processing_time
        )
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ ë¶„ì„ ì „ì²´ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@router.get("/health")
async def health_check():
    """
    ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    
    LLM ì„œë¹„ìŠ¤ ë° OpenAI API ì—°ê²° ìƒíƒœ í™•ì¸
    """
    try:
        # OpenAI API í‚¤ í™•ì¸
        import os
        api_key_exists = bool(os.getenv("OPENAI_API_KEY"))
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë¶„ì„
        if api_key_exists:
            analyzer = TextAnalyzer()
            test_result = analyzer.test_connection()
            openai_status = "connected" if test_result else "error"
        else:
            openai_status = "no_api_key"
        
        return {
            "status": "healthy" if openai_status == "connected" else "degraded",
            "service": "AIRISS LLM Analysis Service",
            "version": "1.0.0",
            "openai_status": openai_status,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@router.get("/usage")
async def get_usage_statistics(db: Session = Depends(get_db)):
    """
    API ì‚¬ìš© í†µê³„
    
    OpenAI API ì‚¬ìš©ëŸ‰ ë° ë¶„ì„ í†µê³„ ë°˜í™˜
    """
    try:
        # ì‹¤ì œë¡œëŠ” DBì—ì„œ í†µê³„ ì¡°íšŒ
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
        return {
            "total_analyses": 1234,
            "today_analyses": 45,
            "average_processing_time": 2.5,
            "openai_tokens_used": 150000,
            "estimated_cost": 3.75,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")