# app/api/upload.py
# AIRISS v4.0 íŒŒì¼ ì—…ë¡œë“œ API - SQLiteService ë©”ì„œë“œ í˜¸ì¶œ ì˜¤ë¥˜ ì™„ì „ í•´ê²° ë²„ì „
# async/await ì²˜ë¦¬ + ì˜¬ë°”ë¥¸ ì¸ì ì „ë‹¬

import os
import uuid
from pathlib import Path
from fastapi import APIRouter, UploadFile, File, Depends, HTTPException, Request
from fastapi.responses import JSONResponse
import pandas as pd
import io
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
import traceback
from sqlalchemy import text
import re
from sqlalchemy.orm import Session
from app.models.file import File as FileRecord
from app.db.database import get_db

# í”„ë¡œì íŠ¸ ë‚´ ëª¨ë“ˆ import
from app.db import db_service
from app.schemas.schemas import FileUploadResponse, FileInfoResponse
from app.api.auth import get_current_user  # ê²½ë¡œ ìˆ˜ì •
from app.utils.encoding_safe import EncodingSafeUtils  # ì¸ì½”ë”© ì•ˆì „ ìœ í‹¸ë¦¬í‹° ì¶”ê°€

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ì—…ë¡œë“œ ë¼ìš°í„° ìƒì„±
router = APIRouter() # prefix ì œê±°
UPLOAD_DIR = Path("uploads") # Added UPLOAD_DIR
UPLOAD_DIR.mkdir(exist_ok=True) # Added UPLOAD_DIR

# ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ì—ì„œ db_serviceë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½

def sanitize_filename(filename: str) -> str:
    """íŒŒì¼ëª…ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ì—¬ ì¸ì½”ë”© ë¬¸ì œë¥¼ ë°©ì§€"""
    try:
        # íŒŒì¼ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€ì€ ìœ ì§€)
        # Windowsì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” ë¬¸ìë“¤ ì œê±°
        safe_filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        
        # ì—°ì†ëœ ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ í•˜ë‚˜ë¡œ ë³€í™˜
        safe_filename = re.sub(r'_+', '_', safe_filename)
        
        # ì•ë’¤ ê³µë°± ë° ì  ì œê±°
        safe_filename = safe_filename.strip(' .')
        
        # ë¹ˆ íŒŒì¼ëª…ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if not safe_filename:
            safe_filename = "uploaded_file"
        
        logger.info(f"ğŸ“ íŒŒì¼ëª… ì•ˆì „í™”: '{filename}' â†’ '{safe_filename}'")
        return safe_filename
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ëª… ì•ˆì „í™” ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ íŒŒì¼ëª… ë°˜í™˜
        return f"file_{uuid.uuid4().hex[:8]}"

@router.post("/upload")
async def upload_file_public(
    file: UploadFile = File(...),
    request: Request = None
):
    """Public file upload endpoint without authentication"""
    try:
        # ê¸°ë³¸ ì‚¬ìš©ì ì •ë³´ (ì¸ì¦ ì—†ìŒ)
        user_id = "anonymous"
        session_id = str(uuid.uuid4())
        logger.info(f"ğŸ“ Public íŒŒì¼ ì—…ë¡œë“œ - Session ID: {session_id}")

        # íŒŒì¼ëª… ì•ˆì „í™” ì²˜ë¦¬
        safe_filename = sanitize_filename(file.filename)
        
        # íŒŒì¼ ì €ì¥
        file_id = generate_file_id()
        file_path = UPLOAD_DIR / f"{file_id}_{safe_filename}"
        
        # íŒŒì¼ ì“°ê¸°
        content = await file.read()
        with open(file_path, "wb") as f:
            f.write(content)
        
        # íŒŒì¼ ì •ë³´ ë°˜í™˜
        return {
            "file_id": file_id,
            "filename": safe_filename,
            "size": len(content),
            "status": "uploaded"
        }
    except Exception as e:
        logger.error(f"ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/simple-upload")
async def upload_file(
    file: UploadFile = File(...),
    request: Request = None,
    current_user: dict = Depends(get_current_user)
):
    try:
        # ì‚¬ìš©ì ì •ë³´ í™•ì¸
        user_id = None
        if current_user:
            user_id = current_user.get('id') or current_user.get('user_id')
        session_id = request.session.get('session_id') if request else None
        if not session_id and request:
            session_id = str(uuid.uuid4())
            request.session['session_id'] = session_id
        logger.info(f"ğŸ“ íŒŒì¼ ì—…ë¡œë“œ - User ID: {user_id}, Session ID: {session_id}")

        # íŒŒì¼ëª… ì•ˆì „í™” ì²˜ë¦¬
        safe_filename = sanitize_filename(file.filename)
        
        # íŒŒì¼ ì €ì¥ (ì•ˆì „í•œ ë°©ì‹)
        file_id = str(uuid.uuid4())
        file_path = UPLOAD_DIR / f"{file_id}_{safe_filename}"
        
        # EncodingSafeUtilsë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•œ ê²½ë¡œ ìƒì„±
        try:
            safe_file_path = EncodingSafeUtils.safe_path_join(str(UPLOAD_DIR), f"{file_id}_{safe_filename}")
            file_path = Path(safe_file_path)
        except Exception as e:
            logger.error(f"âŒ ì•ˆì „í•œ ê²½ë¡œ ìƒì„± ì‹¤íŒ¨: {e}")
            # fallback: ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
            file_path = UPLOAD_DIR / f"{file_id}_{safe_filename}"
        
        # íŒŒì¼ì„ í•œ ë²ˆì— ì½ì–´ì„œ ì•ˆì „í•˜ê²Œ ì €ì¥ (Excel íŒŒì¼ ì†ìƒ ë°©ì§€)
        try:
            # íŒŒì¼ ë‚´ìš©ì„ í•œ ë²ˆì— ì½ê¸°
            file_content = await file.read()
            
            # íŒŒì¼ ì €ì¥
            with open(file_path, "wb") as f:
                f.write(file_content)
            
            # íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦
            if file_path.exists():
                actual_size = file_path.stat().st_size
                expected_size = len(file_content)
                
                if actual_size != expected_size:
                    logger.error(f"âŒ íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: ì˜ˆìƒ {expected_size} bytes, ì‹¤ì œ {actual_size} bytes")
                    # íŒŒì¼ ì‚­ì œ í›„ ì˜¤ë¥˜ ë°œìƒ
                    file_path.unlink(missing_ok=True)
                    raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì¤‘ ì†ìƒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
                
                logger.info(f"âœ… íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦ í†µê³¼: {actual_size} bytes")
            else:
                raise HTTPException(status_code=500, detail="íŒŒì¼ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            # ì €ì¥ ì‹¤íŒ¨ ì‹œ íŒŒì¼ ì •ë¦¬
            file_path.unlink(missing_ok=True)
            raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = file_path.stat().st_size
        logger.info(f"ğŸ“ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path} ({file_size} bytes)")
        
        # íŒŒì¼ ë©”íƒ€ë°ì´í„°
        file_metadata = {
            "id": file_id,
            "filename": file.filename,
            "size": file_size,
            "upload_time": datetime.now(),
            "user_id": user_id,
            "session_id": session_id,
            "file_path": str(file_path)
        }
        
        # DataFrame ìƒì„± ë° ì €ì¥
        try:
            import pandas as pd
            
            # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ DataFrame ìƒì„±
            if file.filename.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(file_path, engine='openpyxl')
            elif file.filename.endswith('.csv'):
                # ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
                encodings = ['utf-8', 'cp949', 'euc-kr', 'iso-8859-1']
                df = None
                for encoding in encodings:
                    try:
                        df = pd.read_csv(file_path, encoding=encoding)
                        break
                    except:
                        continue
                if df is None:
                    raise Exception("CSV íŒŒì¼ ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            else:
                raise Exception("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")
            
            # ì»¬ëŸ¼ ë¶„ì„
            all_columns = list(df.columns)
            
            # UID ì»¬ëŸ¼ ê°ì§€
            uid_keywords = ['uid', 'id', 'ì•„ì´ë””', 'ì‚¬ë²ˆ', 'ì§ì›', 'user', 'emp']
            uid_columns = [col for col in all_columns if any(keyword in col.lower() for keyword in uid_keywords)]
            
            # ì˜ê²¬ ì»¬ëŸ¼ ê°ì§€
            opinion_keywords = ['ì˜ê²¬', 'opinion', 'í‰ê°€', 'feedback', 'ë‚´ìš©', 'ì½”ë©˜íŠ¸', 'í”¼ë“œë°±', 'comment', 'review']
            opinion_columns = [col for col in all_columns if any(keyword in col.lower() for keyword in opinion_keywords)]
            
            # ì •ëŸ‰ë°ì´í„° ì»¬ëŸ¼ ê°ì§€
            quant_keywords = ['ì ìˆ˜', 'score', 'í‰ì ', 'rating', 'ë“±ê¸‰', 'grade', 'level', 'ë‹¬ì„±ë¥ ', 'ë¹„ìœ¨', 'rate', '%', 'percent']
            quantitative_columns = []
            
            for col in all_columns:
                col_lower = col.lower()
                if any(keyword in col_lower for keyword in quant_keywords):
                    # ì‹¤ì œ ë°ì´í„° í™•ì¸
                    sample_data = df[col].dropna().head(10)
                    if len(sample_data) > 0:
                        quantitative_columns.append(col)
            
            # DataFrameì„ pickleë¡œ ì €ì¥
            import pickle
            df_path = file_path.with_suffix('.pkl')
            with open(df_path, 'wb') as f:
                pickle.dump(df, f)
            
            # ë©”íƒ€ë°ì´í„°ì— DataFrame ì •ë³´ ì¶”ê°€
            file_metadata.update({
                "dataframe_path": str(df_path),
                "total_records": len(df),
                "columns": all_columns,
                "uid_columns": uid_columns,
                "opinion_columns": opinion_columns,
                "quantitative_columns": quantitative_columns,
                "airiss_ready": len(uid_columns) > 0 and len(opinion_columns) > 0,
                "hybrid_ready": len(quantitative_columns) > 0
            })
            
            logger.info(f"âœ… DataFrame ìƒì„± ì™„ë£Œ: {len(df)}í–‰, {len(df.columns)}ì—´")
            logger.info(f"  - UID ì»¬ëŸ¼: {uid_columns}")
            logger.info(f"  - ì˜ê²¬ ì»¬ëŸ¼: {opinion_columns}")
            logger.info(f"  - ì •ëŸ‰ ì»¬ëŸ¼: {quantitative_columns}")
            
        except Exception as e:
            logger.error(f"âŒ DataFrame ìƒì„± ì‹¤íŒ¨: {e}")
            # DataFrame ìƒì„± ì‹¤íŒ¨í•´ë„ íŒŒì¼ ë©”íƒ€ë°ì´í„°ëŠ” ì €ì¥
            file_metadata.update({
                "total_records": 0,
                "columns": [],
                "uid_columns": [],
                "opinion_columns": [],
                "quantitative_columns": [],
                "airiss_ready": False,
                "hybrid_ready": False
            })
        
        # DBì— íŒŒì¼ ì •ë³´ ì €ì¥
        db_save_success = False
        try:
            if db_service:
                # DB ì´ˆê¸°í™” í™•ì¸
                await db_service.init_database()
                # files í…Œì´ë¸”ì— ì €ì¥
                await db_service.save_file(file_metadata)
                db_save_success = True
                logger.info(f"âœ… DBì— íŒŒì¼ ì •ë³´ ì €ì¥ ì™„ë£Œ: {file.filename}")
        except Exception as e:
            logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            db_save_success = False
        
        # DB ì €ì¥ ì‹¤íŒ¨ ì‹œ ì„¸ì…˜ì— ì €ì¥
        if not db_save_success and request:
            # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì„¸ì…˜ì— ì €ì¥
            session_file_metadata = file_metadata.copy()
            if isinstance(session_file_metadata.get('upload_time'), datetime):
                session_file_metadata['upload_time'] = session_file_metadata['upload_time'].isoformat()
            
            files_in_session = request.session.get('files', [])
            files_in_session.append(session_file_metadata)
            request.session['files'] = files_in_session
            logger.info(f"ğŸ“‹ ì„¸ì…˜ì— íŒŒì¼ ì •ë³´ ì €ì¥: {file.filename}")
        
        return JSONResponse(content={
            "status": "success",
            "file_id": file_id,
            "filename": file.filename,
            "user_id": user_id,
            "session_id": session_id,
            "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
        })
        
    except Exception as e:
        logger.error(f"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/upload/{file_id}", response_model=FileInfoResponse)
async def get_file_info(
    file_id: str,
):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ ì¡°íšŒ
    - SQLiteServiceì—ì„œ íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    - DataFrame ê¸°ë³¸ ì •ë³´ ì œê³µ
    """
    
    try:
        logger.info(f"ğŸ“‹ íŒŒì¼ ì •ë³´ ì¡°íšŒ ìš”ì²­: {file_id}")
        
        # ğŸ”¥ ìˆ˜ì •ëœ í˜¸ì¶œ: await ì¶”ê°€
        file_record = await db_service.get_file(file_id)
        
        if not file_record:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # get_fileì—ì„œ ì´ë¯¸ dataframeì„ í¬í•¨í•´ì„œ ë°˜í™˜í•˜ë¯€ë¡œ ë³„ë„ ë¡œë“œ ë¶ˆí•„ìš”
        df = file_record.get('dataframe')
        
        if df is None:
            raise HTTPException(status_code=404, detail="íŒŒì¼ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì‹¤ì‹œê°„ ë°ì´í„° ìƒíƒœ í™•ì¸
        current_records = len(df)
        current_columns = len(df.columns)
        
        # datetime ê°ì²´ë¥¼ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def safe_convert_datetime(value):
            if isinstance(value, datetime):
                return value.isoformat()
            elif isinstance(value, str):
                return value
            else:
                return datetime.now().isoformat()
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„± (datetime ì•ˆì „ ì²˜ë¦¬)
        response_data = {
            "file_id": file_id,
            "filename": file_record.get('filename', 'Unknown'),
            "total_records": current_records,
            "column_count": current_columns,
            "columns": [str(col) for col in df.columns.tolist()],
            "uid_columns": file_record.get('uid_columns', []),
            "opinion_columns": file_record.get('opinion_columns', []),
            "quantitative_columns": file_record.get('quantitative_columns', []),
            "upload_time": safe_convert_datetime(file_record.get('upload_time')),
            "file_size": file_record.get('file_size', 0),
            "airiss_ready": file_record.get('airiss_ready', False),
            "hybrid_ready": file_record.get('hybrid_ready', False),
            "data_quality": {
                "text_completeness": file_record.get('text_completeness', 0),
                "quant_completeness": file_record.get('quant_completeness', 0),
                "total_records": current_records
            }
        }
        
        logger.info(f"âœ… íŒŒì¼ ì •ë³´ ì¡°íšŒ ì„±ê³µ: {file_id}")
        return FileInfoResponse(**response_data)
        
    except HTTPException:
        raise
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.delete("/upload/{file_id}")
async def delete_file(
    file_id: str,
):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ
    - SQLiteServiceì—ì„œ íŒŒì¼ ë° DataFrame ë°ì´í„° ì™„ì „ ì‚­ì œ
    """
    
    try:
        logger.info(f"ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ ìš”ì²­: {file_id}")
        
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ğŸ”¥ await ì¶”ê°€)
        file_record = await db_service.get_file(file_id)
        if not file_record:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # íŒŒì¼ ì‚­ì œ (ğŸ”¥ await ì¶”ê°€)
        success = await db_service.delete_file(file_id)
        
        if success:
            logger.info(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_id}")
            return {"message": f"íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤", "file_id": file_id}
        else:
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
    except HTTPException:
        raise
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.get("/files")
async def list_files_pg(db: Session = Depends(get_db)):
    try:
        files = db.query(FileRecord).order_by(FileRecord.upload_time.desc()).all()
        formatted_files = []
        for f in files:
            # columns ì •ë³´ íŒŒì‹±
            columns_list = []
            if f.columns:
                try:
                    columns_list = json.loads(f.columns) if isinstance(f.columns, str) else f.columns
                except:
                    columns_list = []
                    
            formatted_files.append({
                "id": f.id,
                "filename": f.filename,
                "upload_time": f.upload_time.isoformat() if f.upload_time else None,
                "total_records": f.total_records,
                "column_count": len(columns_list),
                "columns": columns_list,  # ì»¬ëŸ¼ ì •ë³´ ì¶”ê°€
                "user_id": f.user_id,
                "session_id": f.session_id
            })
        return JSONResponse(content={
            "status": "success",
            "files": formatted_files,
            "total": len(formatted_files)
        })
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"status": "error", "message": str(e)}
        )

# ë””ë²„ê¹… ì—”ë“œí¬ì¸íŠ¸ ì œê±° (SessionMiddleware datetime ì§ë ¬í™” ë¬¸ì œë¡œ ì¸í•´)
# ëŒ€ì‹  ê°„ë‹¨í•œ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸ ì œê³µ
@router.get("/status")
async def file_api_status():
    """íŒŒì¼ API ìƒíƒœ í™•ì¸ (SessionMiddleware ì˜¤ë¥˜ ì—†ìŒ)"""
    return JSONResponse(content={
        "status": "success",
        "message": "íŒŒì¼ ì—…ë¡œë“œ/ëª©ë¡ ì¡°íšŒ APIê°€ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤",
        "endpoints": {
            "upload": "/api/upload",
            "files": "/api/files",
            "status": "/api/status"
        },
        "note": "ì‹¤ì œ íŒŒì¼ ì—…ë¡œë“œì™€ ëª©ë¡ ì¡°íšŒëŠ” ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤"
    })
