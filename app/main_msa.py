# -*- coding: utf-8 -*-
"""
AIRISS LLM Microservice
OpenAI ê¸°ë°˜ HR ë¶„ì„ ì „ìš© ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤
"""
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import logging
import os
import sys
from pathlib import Path
from datetime import datetime

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

from app.db.database import init_db, engine
from sqlalchemy import inspect

# Logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Create FastAPI app
app = FastAPI(
    title="AIRISS LLM Microservice",
    description="AI-powered HR Analysis Service for EHR Integration",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)

# CORS configuration for EHR integration
allowed_origins = os.getenv("ALLOWED_ORIGINS", "*").split(",")

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=3600,
)

# Request logging middleware
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """ëª¨ë“  ìš”ì²­ ë¡œê¹…"""
    start_time = datetime.now()
    
    # ìš”ì²­ ë¡œê¹…
    logger.info(f"ğŸ“¥ {request.method} {request.url.path}")
    
    # ì‘ë‹µ ì²˜ë¦¬
    response = await call_next(request)
    
    # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    process_time = (datetime.now() - start_time).total_seconds()
    logger.info(f"ğŸ“¤ {request.method} {request.url.path} - {response.status_code} - {process_time:.2f}s")
    
    # ì²˜ë¦¬ ì‹œê°„ì„ í—¤ë”ì— ì¶”ê°€
    response.headers["X-Process-Time"] = str(process_time)
    
    return response

# Startup event
@app.on_event("startup")
async def startup_event():
    """ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    try:
        logger.info("ğŸš€ AIRISS LLM Microservice ì‹œì‘")
        
        # OpenAI API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            logger.info(f"âœ… OpenAI API í‚¤ ë¡œë“œë¨: {api_key[:20]}...")
        else:
            logger.warning("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì„ íƒì‚¬í•­)
        if os.getenv("USE_DATABASE", "false").lower() == "true":
            init_db()
            inspector = inspect(engine)
            tables = inspector.get_table_names()
            logger.info(f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”: {tables}")
        else:
            logger.info("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© ì•ˆ í•¨ (Stateless ëª¨ë“œ)")
        
        logger.info("âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# Root endpoint
@app.get("/")
async def root():
    """ì„œë¹„ìŠ¤ ì •ë³´"""
    return {
        "service": "AIRISS LLM Microservice",
        "version": "1.0.0",
        "status": "operational",
        "description": "AI-powered HR Analysis Service",
        "endpoints": {
            "analyze": "/api/v1/llm/analyze",
            "batch": "/api/v1/llm/batch-analyze",
            "health": "/api/v1/llm/health",
            "docs": "/docs"
        },
        "timestamp": datetime.now().isoformat()
    }

# Health check
@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "service": "AIRISS LLM Microservice",
        "timestamp": datetime.now().isoformat()
    }

# API routers
try:
    from app.api.v1.endpoints.llm_simple import router as llm_router
    logger.info("Using simplified LLM router")
except ImportError:
    from app.api.v1.endpoints.llm_analysis import router as llm_router
    logger.info("Using standard LLM router")

# Register LLM analysis endpoints
app.include_router(llm_router, prefix="/api/v1/llm", tags=["LLM Analysis"])
logger.info("ğŸ“Œ LLM Analysis API ë“±ë¡ ì™„ë£Œ")

# Error handlers
@app.exception_handler(404)
async def not_found_handler(request: Request, exc):
    """404 ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
    return JSONResponse(
        status_code=404,
        content={
            "error": "Not Found",
            "message": f"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {request.url.path}",
            "timestamp": datetime.now().isoformat()
        }
    )

@app.exception_handler(500)
async def internal_error_handler(request: Request, exc):
    """500 ì—ëŸ¬ í•¸ë“¤ëŸ¬"""
    logger.error(f"Internal Server Error: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            "timestamp": datetime.now().isoformat()
        }
    )

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8080))
    logger.info(f"ğŸš€ ì„œë²„ ì‹œì‘: http://0.0.0.0:{port}")
    uvicorn.run(app, host="0.0.0.0", port=port)