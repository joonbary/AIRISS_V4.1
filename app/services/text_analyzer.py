# app/services/text_analyzer.py
"""
AIRISS v4.1 í…ìŠ¤íŠ¸ ë¶„ì„ê¸° - ë”¥ëŸ¬ë‹ NLP ì ìš©
í•œêµ­ì–´ íŠ¹í™” BERT ëª¨ë¸ì„ í™œìš©í•œ ê³ ë„í™”ëœ ê°ì •/ì˜ë„ ë¶„ì„
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import asyncio
import numpy as np
import re
from collections import Counter
import time
import os

logger = logging.getLogger(__name__)

# AIRISS 8ëŒ€ ì˜ì—­ ì •ì˜ (ê¸°ì¡´ ìœ ì§€ + í™•ì¥)
AIRISS_FRAMEWORK = {
    "ì—…ë¬´ì„±ê³¼": {
        "keywords": {
            "positive": [
                "ìš°ìˆ˜", "íƒì›”", "ë›°ì–´ë‚¨", "ì„±ê³¼", "ë‹¬ì„±", "ì™„ë£Œ", "ì„±ê³µ", "íš¨ìœ¨", "ìƒì‚°ì ", 
                "ëª©í‘œë‹¬ì„±", "ì´ˆê³¼ë‹¬ì„±", "í’ˆì§ˆ", "ì •í™•", "ì‹ ì†", "ì™„ë²½", "ì „ë¬¸ì ", "ì²´ê³„ì ",
                "í˜ì‹ ì ", "ì°½ì˜ì ", "ê°œì„ ", "í–¥ìƒ", "ìµœì í™”", "ëŠ¥ìˆ™", "ìˆ™ë ¨", "ì „ë¬¸ì„±"
            ],
            "negative": [
                "ë¶€ì¡±", "ë¯¸í¡", "ì§€ì—°", "ì‹¤íŒ¨", "ë¬¸ì œ", "ì˜¤ë¥˜", "ëŠ¦ìŒ", "ë¹„íš¨ìœ¨", 
                "ëª©í‘œë¯¸ë‹¬", "í’ˆì§ˆì €í•˜", "ë¶€ì •í™•", "ë¯¸ì™„ì„±", "ë¶€ì‹¤", "ê°œì„ í•„ìš”", "ë¯¸ë‹¬"
            ]
        },
        "weight": 0.25,
        "description": "ì—…ë¬´ ì‚°ì¶œë¬¼ì˜ ì–‘ê³¼ ì§ˆ",
        "bert_aspects": ["ì—…ë¬´ í’ˆì§ˆ", "ëª©í‘œ ë‹¬ì„±ë„", "ìƒì‚°ì„±", "íš¨ìœ¨ì„±"]
    },
    "KPIë‹¬ì„±": {
        "keywords": {
            "positive": [
                "KPIë‹¬ì„±", "ì§€í‘œë‹¬ì„±", "ëª©í‘œì´ˆê³¼", "ì„±ê³¼ìš°ìˆ˜", "ì‹¤ì ìš°ìˆ˜", "ë§¤ì¶œì¦ê°€", 
                "íš¨ìœ¨í–¥ìƒ", "ìƒì‚°ì„±í–¥ìƒ", "ìˆ˜ì¹˜ë‹¬ì„±", "ì„±ì¥", "ê°œì„ ", "ìƒìŠ¹", "ì¦ê°€"
            ],
            "negative": [
                "KPIë¯¸ë‹¬", "ëª©í‘œë¯¸ë‹¬", "ì‹¤ì ë¶€ì§„", "ë§¤ì¶œê°ì†Œ", "íš¨ìœ¨ì €í•˜", 
                "ìƒì‚°ì„±ì €í•˜", "ìˆ˜ì¹˜ë¶€ì¡±", "í•˜ë½", "í‡´ë³´", "ê°ì†Œ", "ì •ì²´"
            ]
        },
        "weight": 0.20,
        "description": "í•µì‹¬ì„±ê³¼ì§€í‘œ ë‹¬ì„±ë„",
        "bert_aspects": ["ì •ëŸ‰ì  ì„±ê³¼", "ëª©í‘œ ëŒ€ë¹„ ì‹¤ì ", "ì„±ì¥ë¥ "]
    },
    "íƒœë„ë§ˆì¸ë“œ": {
        "keywords": {
            "positive": [
                "ì ê·¹ì ", "ê¸ì •ì ", "ì—´ì •", "ì„±ì‹¤", "ì±…ì„ê°", "ì§„ì·¨ì ", "í˜‘ì¡°ì ", 
                "ì„±ì¥ì§€í–¥", "í•™ìŠµì˜ì§€", "ë„ì „ì •ì‹ ", "ì£¼ì¸ì˜ì‹", "í—Œì‹ ", "ëª°ì…", "ì—´ì˜"
            ],
            "negative": [
                "ì†Œê·¹ì ", "ë¶€ì •ì ", "ë¬´ê´€ì‹¬", "ë¶ˆì„±ì‹¤", "íšŒí”¼", "ëƒ‰ì†Œì ", 
                "ë¹„í˜‘ì¡°ì ", "ì•ˆì£¼", "í˜„ìƒìœ ì§€", "ìˆ˜ë™ì ", "ë¬´ê¸°ë ¥", "íƒœë§Œ"
            ]
        },
        "weight": 0.15,
        "description": "ì—…ë¬´ì— ëŒ€í•œ íƒœë„ì™€ ë§ˆì¸ë“œì…‹",
        "bert_aspects": ["ì ê·¹ì„±", "ì±…ì„ê°", "ì—´ì •", "ì„±ì¥ ë§ˆì¸ë“œì…‹"]
    },
    "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜": {
        "keywords": {
            "positive": [
                "ëª…í™•", "ì •í™•", "ì‹ ì†", "ì¹œì ˆ", "ê²½ì²­", "ì†Œí†µ", "ì „ë‹¬", "ì´í•´", 
                "ì„¤ë“", "í˜‘ì˜", "ì¡°ìœ¨", "ê³µìœ ", "íˆ¬ëª…", "ê°œë°©ì ", "ì›í™œ", "íš¨ê³¼ì "
            ],
            "negative": [
                "ë¶ˆëª…í™•", "ì§€ì—°", "ë¬´ì‹œ", "ì˜¤í•´", "ë‹¨ì ˆ", "ì¹¨ë¬µ", "íšŒí”¼", 
                "ë…ë‹¨", "ì¼ë°©ì ", "íì‡„ì ", "ì†Œí†µë¶€ì¡±", "ì „ë‹¬ë¯¸í¡", "ê°ˆë“±"
            ]
        },
        "weight": 0.15,
        "description": "ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ê³¼ ìŠ¤íƒ€ì¼",
        "bert_aspects": ["ëª…í™•ì„±", "ì ì‹œì„±", "ê³µê°ëŠ¥ë ¥", "ì„¤ë“ë ¥"]
    },
    "ë¦¬ë”ì‹­í˜‘ì—…": {
        "keywords": {
            "positive": [
                "ë¦¬ë”ì‹­", "íŒ€ì›Œí¬", "í˜‘ì—…", "ì§€ì›", "ë©˜í† ë§", "ë™ê¸°ë¶€ì—¬", "ì¡°ìœ¨", 
                "í™”í•©", "íŒ€ë¹Œë”©", "ìœ„ì„", "ì½”ì¹­", "ì˜í–¥ë ¥", "ì¡´ì¤‘", "ë°°ë ¤", "ê³µìœ "
            ],
            "negative": [
                "ë…ë‹¨", "ê°ˆë“±", "ë¹„í˜‘ì¡°", "ì†Œì™¸", "ë¶„ì—´", "ëŒ€ë¦½", "ì´ê¸°ì£¼ì˜", 
                "ë°©í•´", "ë¬´ê´€ì‹¬", "ê³ ë¦½", "ê°œì¸ì£¼ì˜", "ê¶Œìœ„ì ", "ê°•ì••ì "
            ]
        },
        "weight": 0.10,
        "description": "ë¦¬ë”ì‹­ê³¼ í˜‘ì—… ëŠ¥ë ¥",
        "bert_aspects": ["íŒ€ ê¸°ì—¬ë„", "ë¦¬ë”ì‹­ ìŠ¤íƒ€ì¼", "í˜‘ì—… ìì„¸"]
    },
    "ì „ë¬¸ì„±í•™ìŠµ": {
        "keywords": {
            "positive": [
                "ì „ë¬¸", "ìˆ™ë ¨", "ê¸°ìˆ ", "ì§€ì‹", "í•™ìŠµ", "ë°œì „", "ì—­ëŸ‰", "ëŠ¥ë ¥", 
                "ì„±ì¥", "í–¥ìƒ", "ìŠµë“", "ê°œë°œ", "ì „ë¬¸ì„±", "ë…¸í•˜ìš°", "í˜ì‹ ", "ì—°êµ¬"
            ],
            "negative": [
                "ë¯¸ìˆ™", "ë¶€ì¡±", "ë‚™í›„", "ë¬´ì§€", "ì •ì²´", "í‡´ë³´", "ë¬´ëŠ¥ë ¥", 
                "ê¸°ì´ˆë¶€ì¡±", "ì—­ëŸ‰ë¶€ì¡±", "ì‹¤ë ¥ë¶€ì¡±", "ê°œì„ í•„ìš”", "í•™ìŠµë¶€ì§„"
            ]
        },
        "weight": 0.08,
        "description": "ì „ë¬¸ì„±ê³¼ í•™ìŠµëŠ¥ë ¥",
        "bert_aspects": ["ì „ë¬¸ ì§€ì‹", "í•™ìŠµ ì†ë„", "ê¸°ìˆ  ìˆ™ë ¨ë„"]
    },
    "ì°½ì˜í˜ì‹ ": {
        "keywords": {
            "positive": [
                "ì°½ì˜", "í˜ì‹ ", "ì•„ì´ë””ì–´", "ê°œì„ ", "íš¨ìœ¨í™”", "ìµœì í™”", "ìƒˆë¡œìš´", 
                "ë„ì „", "ë³€í™”", "ë°œìƒ", "ì°½ì¡°", "í˜ì‹ ì ", "ë…ì°½ì ", "ì„ ë„ì "
            ],
            "negative": [
                "ë³´ìˆ˜ì ", "ê²½ì§", "í‹€ì—ë°•íŒ", "ë³€í™”ê±°ë¶€", "ê¸°ì¡´ë°©ì‹", "ê´€ìŠµì ", 
                "ê²½ì§ëœ", "ê³ ì •ì ", "ë³€í™”ì—†ì´", "êµ¬íƒœì˜ì—°", "ë§¤ë„ˆë¦¬ì¦˜"
            ]
        },
        "weight": 0.05,
        "description": "ì°½ì˜ì„±ê³¼ í˜ì‹  ë§ˆì¸ë“œ",
        "bert_aspects": ["ì°½ì˜ì„±", "í˜ì‹  ì˜ì§€", "ë³€í™” ìˆ˜ìš©ì„±"]
    },
    "ì¡°ì§ì ì‘": {
        "keywords": {
            "positive": [
                "ì ì‘", "ìœµí™”", "ì¡°í™”", "ë¬¸í™”", "ê·œì¹™ì¤€ìˆ˜", "ìœ¤ë¦¬", "ì‹ ë¢°", 
                "ì•ˆì •", "ì¼ê´€ì„±", "ì„±ì‹¤ì„±", "ì¡°ì§", "íšŒì‚¬", "ì¶©ì„±", "ì†Œì†ê°"
            ],
            "negative": [
                "ë¶€ì ì‘", "ê°ˆë“±", "ìœ„ë°˜", "ë¹„ìœ¤ë¦¬", "ë¶ˆì‹ ", "ì¼íƒˆ", 
                "ë¬¸ì œí–‰ë™", "ê·œì •ìœ„ë°˜", "ì¡°ì§ê³¼", "ì´íƒˆ", "ë¶ˆí™”"
            ]
        },
        "weight": 0.02,
        "description": "ì¡°ì§ë¬¸í™” ì ì‘ë„ì™€ ìœ¤ë¦¬ì„±",
        "bert_aspects": ["ì¡°ì§ ì ì‘ë ¥", "ìœ¤ë¦¬ì„±", "ê·œì • ì¤€ìˆ˜"]
    }
}

class AIRISSTextAnalyzer:
    """AIRISS v4.1 ë”¥ëŸ¬ë‹ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.framework = AIRISS_FRAMEWORK
        self.openai_available = False
        self.openai = None
        self.bert_model = None
        self.bias_detector = None
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_models()
        
    def _initialize_models(self):
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ ì´ˆê¸°í™”"""
        # OpenAI ëª¨ë“ˆ ì²´í¬
        try:
            import openai
            self.openai = openai
            self.openai_available = True
            logger.info("âœ… OpenAI ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
        except ImportError as e:
            logger.warning(f"âš ï¸ OpenAI ëª¨ë“ˆ ì—†ìŒ - ê³ ê¸‰ AI ë¶„ì„ ì œí•œë¨: {e}")
            self.openai_available = False
        except Exception as e:
            logger.error(f"OpenAI ëª¨ë“ˆ ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            self.openai_available = False
        
        # í•œêµ­ì–´ BERT ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„
        try:
            from transformers import AutoTokenizer, AutoModelForSequenceClassification
            import torch
            
            # KcELECTRA ë˜ëŠ” KoBERT ëª¨ë¸ ì‚¬ìš©
            model_name = "beomi/KcELECTRA-base-v2022"
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.bert_model = AutoModelForSequenceClassification.from_pretrained(model_name)
            logger.info(f"âœ… í•œêµ­ì–´ BERT ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
        except ImportError:
            logger.warning("âš ï¸ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - BERT ê¸°ë°˜ ë¶„ì„ ë¹„í™œì„±í™”")
            self.bert_model = None
        except Exception as e:
            logger.error(f"BERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.bert_model = None
        
        # í¸í–¥ì„± íƒì§€ê¸° ì´ˆê¸°í™”
        from app.services.bias_detection import BiasDetector
        self.bias_detector = BiasDetector()
    
    async def analyze_text(
        self, 
        uid: str, 
        opinion: str,
        enable_ai: bool = False,
        api_key: Optional[str] = None,
        model: str = "gpt-3.5-turbo",
        max_tokens: int = 1500
    ) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ë¶„ì„ ë° AI í”¼ë“œë°± ìƒì„± í†µí•© í•¨ìˆ˜"""
        
        # 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„ ìˆ˜í–‰
        basic_analysis = await self._perform_basic_analysis(uid, opinion)
        
        # 2. AI í”¼ë“œë°± ìƒì„± (í™œì„±í™”ëœ ê²½ìš°)
        ai_feedback = {}
        if enable_ai and api_key:
            logger.info(f"ğŸ¤– AI í”¼ë“œë°± ìƒì„± ì‹œì‘ - UID: {uid}")
            ai_feedback = await self.generate_ai_feedback(
                uid, opinion, api_key, model, max_tokens
            )
            logger.info(f"âœ… AI í”¼ë“œë°± ìƒì„± ì™„ë£Œ - UID: {uid}")
        else:
            logger.info(f"âš ï¸ AI í”¼ë“œë°± ê±´ë„ˆëœ€ - enable_ai: {enable_ai}, api_key: {'ìˆìŒ' if api_key else 'ì—†ìŒ'}")
        
        # 3. ê²°ê³¼ í†µí•©
        return {
            **basic_analysis,
            "ai_feedback": ai_feedback
        }
    
    async def _perform_basic_analysis(self, uid: str, opinion: str) -> Dict[str, Any]:
        """ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„"""
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        cleaned_text = self._preprocess_text(opinion)
        
        # 8ëŒ€ ì˜ì—­ë³„ ë¶„ì„
        dimension_results = {}
        for dimension, config in self.framework.items():
            score = self._analyze_dimension(cleaned_text, config)
            dimension_results[dimension] = {
                "score": score,
                "weight": config["weight"],
                "weighted_score": score * config["weight"]
            }
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        overall_score = sum(r["weighted_score"] for r in dimension_results.values())
        
        # ê°ì • ë¶„ì„
        sentiment = self._analyze_sentiment(cleaned_text)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(cleaned_text)
        
        return {
            "uid": uid,
            "overall_score": round(overall_score, 1),
            "dimension_scores": dimension_results,
            "sentiment": sentiment,
            "keywords": keywords,
            "text_length": len(cleaned_text),
            "analysis_version": "AIRISS v4.1"
        }
    
    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # ê¸°ë³¸ ì •ë¦¬
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
        return text.strip()
    
    def _analyze_dimension(self, text: str, config: Dict) -> float:
        """ê°œë³„ ì˜ì—­ ë¶„ì„"""
        positive_score = 0
        negative_score = 0
        
        # ê¸ì • í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword in config["keywords"]["positive"]:
            if keyword in text:
                positive_score += 1
        
        # ë¶€ì • í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword in config["keywords"]["negative"]:
            if keyword in text:
                negative_score += 1
        
        # ì ìˆ˜ ê³„ì‚° (0-100)
        if positive_score + negative_score == 0:
            return 50.0  # ì¤‘ë¦½
        
        score = (positive_score / (positive_score + negative_score)) * 100
        return min(100, max(0, score))
    
    def analyze_text(self, opinion: str, dimension: str) -> Dict:
        """íŠ¹ì • ì°¨ì›ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ë¶„ì„ (ê¸°ì¡´ hybrid_analyzer í˜¸í™˜ìš©)"""
        if dimension not in self.framework:
            return {
                "score": 50.0, 
                "confidence": 50,
                "signals": {
                    "positive_words": [],
                    "negative_words": []
                }
            }
        
        config = self.framework[dimension]
        text = self._preprocess_text(opinion)
        score = self._analyze_dimension(text, config)
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ê²°ê³¼ ìˆ˜ì§‘
        positive_words = []
        negative_words = []
        
        for keyword in config["keywords"]["positive"]:
            if keyword in text:
                positive_words.append(keyword)
        
        for keyword in config["keywords"]["negative"]:
            if keyword in text:
                negative_words.append(keyword)
        
        return {
            "score": score,
            "confidence": 70,
            "signals": {
                "positive_words": positive_words[:5],  # ìµœëŒ€ 5ê°œ
                "negative_words": negative_words[:5]   # ìµœëŒ€ 5ê°œ
            }
        }
    
    def calculate_overall_score(self, dimension_scores: Dict[str, float]) -> Dict:
        """8ëŒ€ ì˜ì—­ ì ìˆ˜ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        weighted_score = 0
        total_weight = 0
        
        for dimension, score in dimension_scores.items():
            if dimension in self.framework:
                weight = self.framework[dimension]["weight"]
                weighted_score += score * weight
                total_weight += weight
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        if total_weight > 0:
            overall_score = weighted_score / total_weight
        else:
            overall_score = 50.0
        
        # ë“±ê¸‰ ê³„ì‚°
        if overall_score >= 90:
            grade = "S"
        elif overall_score >= 80:
            grade = "A"
        elif overall_score >= 70:
            grade = "B"
        elif overall_score >= 60:
            grade = "C"
        elif overall_score >= 50:
            grade = "D"
        else:
            grade = "F"
        
        return {
            "overall_score": round(overall_score, 1),
            "grade": grade,
            "confidence": 75  # ê¸°ë³¸ ì‹ ë¢°ë„
        }
    
    def _analyze_sentiment(self, text: str) -> Dict[str, float]:
        """ê°ì • ë¶„ì„"""
        positive_words = ["ì¢‹ë‹¤", "ìš°ìˆ˜", "ë›°ì–´ë‚˜ë‹¤", "í›Œë¥­", "ìµœê³ "]
        negative_words = ["ë‚˜ì˜ë‹¤", "ë¶€ì¡±", "ë¯¸í¡", "ë¬¸ì œ", "ê°œì„ "]
        
        pos_count = sum(1 for word in positive_words if word in text)
        neg_count = sum(1 for word in negative_words if word in text)
        
        total = pos_count + neg_count
        if total == 0:
            return {"positive": 0.5, "negative": 0.5, "neutral": 0.0}
        
        return {
            "positive": pos_count / total,
            "negative": neg_count / total,
            "neutral": 0.0
        }
    
    def _extract_keywords(self, text: str, top_n: int = 5) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        words = text.split()
        word_freq = Counter(words)
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {"ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì—", "ì—ì„œ", "ìœ¼ë¡œ", "ì™€", "ê³¼"}
        filtered_words = [(word, freq) for word, freq in word_freq.items() 
                         if word not in stopwords and len(word) > 1]
        
        # ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
        sorted_words = sorted(filtered_words, key=lambda x: x[1], reverse=True)
        return [word for word, _ in sorted_words[:top_n]]
    
    async def generate_ai_feedback(
        self,
        uid: str,
        opinion: str,
        api_key: str,
        model: str = "gpt-3.5-turbo",
        max_tokens: int = 1500
    ) -> Dict[str, Any]:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ AI í”¼ë“œë°± ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        
        if not self.openai_available:
            logger.error("OpenAI ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return self._get_fallback_response("OpenAI ëª¨ë“ˆ ë¯¸ì„¤ì¹˜")
        
        if not api_key:
            logger.error("OpenAI API í‚¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return self._get_fallback_response("API í‚¤ ì—†ìŒ")
        
        # ì¬ì‹œë„ ë¡œì§
        max_retries = 3
        retry_delay = 2  # seconds
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ”„ OpenAI API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{max_retries} - UID: {uid}")
                
                # API í‚¤ ìœ íš¨ì„± ê²€ì¦
                if not api_key:
                    logger.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                    raise ValueError("OpenAI API í‚¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
                # API í‚¤ ì •ë¦¬ (ê³µë°± ì œê±°)
                cleaned_api_key = api_key.strip()
                
                # API í‚¤ í˜•ì‹ ê²€ì¦ (sk-ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸)
                if not cleaned_api_key.startswith('sk-') and not cleaned_api_key.startswith('sess-'):
                    logger.error(f"ì˜ëª»ëœ API í‚¤ í˜•ì‹: {cleaned_api_key[:10]}...")
                    raise ValueError("ì˜¬ë°”ë¥¸ OpenAI API í‚¤ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                
                # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¶”ê°€)
                try:
                    import httpx
                    # Railway í™˜ê²½ì—ì„œ ì—°ê²° ì‹œê°„ ì¦ê°€
                    client = self.openai.OpenAI(
                        api_key=cleaned_api_key,
                        timeout=httpx.Timeout(60.0, connect=30.0),  # ì—°ê²° íƒ€ì„ì•„ì›ƒ 30ì´ˆ, ì „ì²´ 60ì´ˆ
                        max_retries=2  # ì¬ì‹œë„ íšŸìˆ˜ ì œí•œ
                    )
                except Exception as client_error:
                    logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {client_error}")
                    raise ValueError(f"API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(client_error)}")
                
                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = self._create_analysis_prompt(uid, opinion)
                
                # í”„ë¡ì‹œ ì‚¬ìš© ì‹œë„ (í•­ìƒ ì‹œë„, Railway í™˜ê²½ì´ ì•„ë‹ˆì–´ë„ ê°€ëŠ¥)
                logger.info("ğŸ”„ OpenAI API í˜¸ì¶œ: í”„ë¡ì‹œ ì—°ê²° ì‹œë„")
                try:
                    response = await self._use_internal_proxy(prompt, model, max_tokens)
                    if response:
                        logger.info("âœ… ë‚´ë¶€ í”„ë¡ì‹œë¥¼ í†µí•œ OpenAI API í˜¸ì¶œ ì„±ê³µ")
                    else:
                        raise Exception("í”„ë¡ì‹œ ì‘ë‹µì´ ë¹„ì–´ìˆìŒ")
                except Exception as proxy_error:
                    logger.warning(f"âš ï¸ ë‚´ë¶€ í”„ë¡ì‹œ ì‹¤íŒ¨, ì§ì ‘ ì—°ê²° ì‹œë„: {proxy_error}")
                    # í”„ë¡ì‹œ ì‹¤íŒ¨ì‹œ ì§ì ‘ ì—°ê²° ì‹œë„
                    response = await self._direct_openai_call(client, prompt, model, max_tokens)
                
                # ì‘ë‹µ ì²˜ë¦¬
                if response and response.choices and len(response.choices) > 0:
                    feedback = response.choices[0].message.content
                    logger.info(f"âœ… OpenAI API í˜¸ì¶œ ì„±ê³µ - UID: {uid}")
                    return self._parse_ai_response(feedback)
                else:
                    logger.error("OpenAI API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                    raise ValueError("API ì‘ë‹µ ì—†ìŒ")
                    
            except asyncio.TimeoutError:
                logger.warning(f"â±ï¸ OpenAI API íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                    continue
                return self._get_fallback_response("API íƒ€ì„ì•„ì›ƒ")
                
            except Exception as e:
                error_msg = str(e)
                error_type = type(e).__name__
                logger.error(f"âŒ OpenAI API ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries})")
                logger.error(f"   ì˜¤ë¥˜ íƒ€ì…: {error_type}")
                logger.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {error_msg}")
                
                # ì—°ê²° ì‹¤íŒ¨ ì²˜ë¦¬
                if "connection" in error_msg.lower():
                    logger.error("ğŸ”¥ OpenAI API ì—°ê²° ì‹¤íŒ¨")
                    logger.error("   ê°€ëŠ¥í•œ ì›ì¸:")
                    logger.error("   1. ë„¤íŠ¸ì›Œí¬ ì •ì±…ìœ¼ë¡œ ì™¸ë¶€ API í˜¸ì¶œ ì°¨ë‹¨")
                    logger.error("   2. OpenAI ì„œë²„ ì¼ì‹œì  ë¬¸ì œ")
                    logger.error("   3. ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ")
                    logger.info("ğŸ’¡ í•´ê²° ë°©ë²•: AI ë¶„ì„ì„ ë¹„í™œì„±í™”í•˜ê³  ì§„í–‰í•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”")
                
                # API í‚¤ ê´€ë ¨ ì˜¤ë¥˜ ì²˜ë¦¬
                if "api_key" in error_msg.lower() or "authentication" in error_msg.lower() or "unauthorized" in error_msg.lower():
                    logger.error("API í‚¤ ì¸ì¦ ì‹¤íŒ¨")
                    return self._get_fallback_response("API í‚¤ ì¸ì¦ ì‹¤íŒ¨ - ì˜¬ë°”ë¥¸ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
                
                # ì¬ì‹œë„ ê°€ëŠ¥í•œ ì˜¤ë¥˜ì¸ì§€ í™•ì¸
                if "connection" in error_msg.lower() or "timeout" in error_msg.lower() or "network" in error_msg.lower():
                    if attempt < max_retries - 1:
                        wait_time = retry_delay * (attempt + 1)
                        logger.info(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                        await asyncio.sleep(wait_time)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                        continue
                
                # ì†ë„ ì œí•œ ì˜¤ë¥˜
                if "rate" in error_msg.lower() or "limit" in error_msg.lower():
                    if attempt < max_retries - 1:
                        wait_time = retry_delay * (2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                        logger.info(f"â³ ì†ë„ ì œí•œ - {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                        await asyncio.sleep(wait_time)
                        continue
                
                # ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜
                return self._get_fallback_response(f"AI ë¶„ì„ ì˜¤ë¥˜: {error_msg}")
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        logger.error(f"âŒ OpenAI API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨ - UID: {uid}")
        return self._get_fallback_response("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
    
    async def _use_internal_proxy(self, prompt: str, model: str, max_tokens: int) -> Any:
        """ë‚´ë¶€ í”„ë¡ì‹œë¥¼ í†µí•œ OpenAI API í˜¸ì¶œ"""
        import httpx
        
        # Railway í™˜ê²½ì—ì„œëŠ” localhost ì‚¬ìš©
        base_url = "http://localhost:8080"
        
        request_data = {
            "model": model,
            "messages": [
                {
                    "role": "system", 
                    "content": "ë‹¹ì‹ ì€ OKê¸ˆìœµê·¸ë£¹ì˜ ìˆ˜ì„ HR ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê±´ì„¤ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”."
                },
                {"role": "user", "content": prompt}
            ],
            "max_tokens": max_tokens,
            "temperature": 0.7
        }
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"{base_url}/api/v1/proxy/openai/chat/completions",
                json=request_data
            )
            
            if response.status_code == 200:
                result = response.json()
                # OpenAI ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                if "choices" in result:
                    return type('MockResponse', (), {
                        'choices': [type('Choice', (), {
                            'message': type('Message', (), {
                                'content': result["choices"][0]["message"]["content"]
                            })()
                        })()]
                    })()
                else:
                    raise Exception("Invalid response format")
            else:
                raise Exception(f"í”„ë¡ì‹œ ì˜¤ë¥˜: {response.status_code}")
    
    async def _direct_openai_call(self, client, prompt: str, model: str, max_tokens: int) -> Any:
        """ì§ì ‘ OpenAI API í˜¸ì¶œ"""
        import asyncio
        
        # íƒ€ì„ì•„ì›ƒì„ 30ì´ˆë¡œ ì„¤ì •
        response = await asyncio.wait_for(
            asyncio.get_event_loop().run_in_executor(
                None,
                lambda: client.chat.completions.create(
                    model=model,
                    messages=[
                        {
                            "role": "system", 
                            "content": "ë‹¹ì‹ ì€ OKê¸ˆìœµê·¸ë£¹ì˜ ìˆ˜ì„ HR ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê±´ì„¤ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=max_tokens,
                    temperature=0.7,
                    timeout=30  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                )
            ),
            timeout=35  # asyncio íƒ€ì„ì•„ì›ƒì€ ì•½ê°„ ë” ê¸¸ê²Œ
        )
        return response
    
    def _create_analysis_prompt(self, uid: str, opinion: str) -> str:
        """AI ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
ì§ì› {uid}ì˜ í‰ê°€ ì˜ê²¬ì„ AIRISS 8ëŒ€ ì˜ì—­ ê¸°ë°˜ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„í•˜ì„¸ìš”:

í‰ê°€ ì˜ê²¬: {opinion[:1500]}

8ëŒ€ ì˜ì—­:
1. ì—…ë¬´ì„±ê³¼ (25%) - ì—…ë¬´ í’ˆì§ˆ, ìƒì‚°ì„±, ëª©í‘œ ë‹¬ì„±
2. KPIë‹¬ì„± (20%) - ì •ëŸ‰ì  ì„±ê³¼, ì§€í‘œ ë‹¬ì„±ë¥ 
3. íƒœë„ë§ˆì¸ë“œ (15%) - ì ê·¹ì„±, ì±…ì„ê°, ì„±ì¥ ì˜ì§€
4. ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ (15%) - ì†Œí†µ ëŠ¥ë ¥, í˜‘ë ¥ì  ëŒ€í™”
5. ë¦¬ë”ì‹­í˜‘ì—… (10%) - íŒ€ì›Œí¬, ë¦¬ë”ì‹­, ì˜í–¥ë ¥
6. ì „ë¬¸ì„±í•™ìŠµ (8%) - ê¸°ìˆ  ì—­ëŸ‰, í•™ìŠµ ì†ë„
7. ì°½ì˜í˜ì‹  (5%) - ì°½ì˜ì„±, ë³€í™” ì£¼ë„
8. ì¡°ì§ì ì‘ (2%) - ì¡°ì§ ë¬¸í™” ì ì‘, ìœ¤ë¦¬ì„±

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”:

[í•µì‹¬ ê°•ì ] (3ê°€ì§€)
- ê°•ì 1: (ì˜ì—­ëª…) êµ¬ì²´ì  í–‰ë™/ì„±ê³¼
- ê°•ì 2: (ì˜ì—­ëª…) êµ¬ì²´ì  í–‰ë™/ì„±ê³¼
- ê°•ì 3: (ì˜ì—­ëª…) êµ¬ì²´ì  í–‰ë™/ì„±ê³¼

[ê°œì„  í•„ìš”ì‚¬í•­] (3ê°€ì§€)
- ê°œì„ 1: (ì˜ì—­ëª…) êµ¬ì²´ì  ê°œì„ ì 
- ê°œì„ 2: (ì˜ì—­ëª…) êµ¬ì²´ì  ê°œì„ ì 
- ê°œì„ 3: (ì˜ì—­ëª…) êµ¬ì²´ì  ê°œì„ ì 

[ì¢…í•© í”¼ë“œë°±]
- í˜„ì¬ ìˆ˜ì¤€: (1-2ë¬¸ì¥)
- ì„±ì¥ ì ì¬ë ¥: (1-2ë¬¸ì¥)
- í•µì‹¬ ì œì–¸: (1-2ë¬¸ì¥)

[êµ¬ì²´ì  ì‹¤í–‰ ê³„íš] (3ê°€ì§€)
1. ë‹¨ê¸°(1ê°œì›”): êµ¬ì²´ì  ì•¡ì…˜
2. ì¤‘ê¸°(3ê°œì›”): êµ¬ì²´ì  ëª©í‘œ
3. ì¥ê¸°(6ê°œì›”): ê¸°ëŒ€ ì„±ê³¼
"""
    
    def _parse_ai_response(self, feedback: str) -> Dict[str, Any]:
        """AI ì‘ë‹µ íŒŒì‹±"""
        sections = {
            "strengths": "",
            "weaknesses": "",
            "overall": "",
            "action_plan": []
        }
        
        try:
            if "[í•µì‹¬ ê°•ì ]" in feedback:
                parts = feedback.split("[í•µì‹¬ ê°•ì ]")[1].split("[ê°œì„  í•„ìš”ì‚¬í•­]")
                sections["strengths"] = parts[0].strip() if len(parts) > 0 else ""
                
                if len(parts) > 1:
                    parts2 = parts[1].split("[ì¢…í•© í”¼ë“œë°±]")
                    sections["weaknesses"] = parts2[0].strip() if len(parts2) > 0 else ""
                    
                    if len(parts2) > 1:
                        parts3 = parts2[1].split("[êµ¬ì²´ì  ì‹¤í–‰ ê³„íš]")
                        sections["overall"] = parts3[0].strip() if len(parts3) > 0 else ""
                        
                        if len(parts3) > 1:
                            action_items = parts3[1].strip().split('\n')
                            sections["action_plan"] = [item.strip() for item in action_items if item.strip()]
            else:
                # êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ì‘ë‹µ ì²˜ë¦¬
                sections["overall"] = feedback.strip()
                
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            sections["overall"] = feedback.strip()
        
        return {
            "ai_strengths": sections["strengths"],
            "ai_weaknesses": sections["weaknesses"],
            "ai_feedback": sections["overall"],
            "ai_recommendations": sections["action_plan"],
            "error": None
        }
    
    def _get_fallback_response(self, error_reason: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‹œ í´ë°± ì‘ë‹µ"""
        logger.warning(f"AI ë¶„ì„ í´ë°± ì‘ë‹µ ì‚¬ìš©: {error_reason}")
        
        # ì˜¤ë¥˜ íƒ€ì…ë³„ ë©”ì‹œì§€
        if "connection" in error_reason.lower():
            message = "OpenAI API ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ í™•ì¸í•˜ê±°ë‚˜ AI ë¶„ì„ì„ ë¹„í™œì„±í™”í•˜ê³  ì§„í–‰í•˜ì„¸ìš”."
        elif "timeout" in error_reason.lower():
            message = "OpenAI API ì‘ë‹µ ì‹œê°„ ì´ˆê³¼. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ AI ë¶„ì„ì„ ë¹„í™œì„±í™”í•˜ì„¸ìš”."
        elif "api" in error_reason.lower() and "key" in error_reason.lower():
            message = "OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        elif "rate" in error_reason.lower():
            message = "OpenAI API ìš”ì²­ í•œë„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ AI ë¶„ì„ì„ ë¹„í™œì„±í™”í•˜ì„¸ìš”."
        else:
            message = f"AI ë¶„ì„ ì‹¤íŒ¨: {error_reason}. AI ë¶„ì„ì„ ë¹„í™œì„±í™”í•˜ê³  ì§„í–‰í•˜ì„¸ìš”."
        
        return {
            "ai_strengths": "í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "ai_weaknesses": "AI ë¶„ì„ ì—†ì´ ê¸°ë³¸ í‰ê°€ë§Œ ì œê³µë©ë‹ˆë‹¤.",
            "ai_feedback": message,
            "ai_recommendations": ["í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ í‰ê°€í•´ì£¼ì„¸ìš”."],
            "error": error_reason
        }


class BiasDetector:
    """í¸í–¥ì„± íƒì§€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.bias_patterns = {
            "gender": ["ì—¬ì„±", "ë‚¨ì„±", "ì—¬ì", "ë‚¨ì", "ê·¸ë…€", "ê·¸"],
            "age": ["ë‚˜ì´", "ì—°ë ¹", "ì Šì€", "ëŠ™ì€", "ì‹ ì…", "ê²½ë ¥"],
            "appearance": ["ì™¸ëª¨", "ìƒê¹€ìƒˆ", "í‚¤", "ëª¸ë¬´ê²Œ", "ì²´ê²©"],
            "personal": ["ê²°í˜¼", "ìë…€", "ê°€ì¡±", "ì¢…êµ", "ì •ì¹˜"]
        }
    
    def detect_bias(self, text: str) -> Dict[str, Any]:
        """í¸í–¥ì„± íƒì§€"""
        detected_biases = []
        
        for bias_type, keywords in self.bias_patterns.items():
            for keyword in keywords:
                if keyword in text:
                    detected_biases.append({
                        "type": bias_type,
                        "keyword": keyword,
                        "severity": "medium"
                    })
        
        return {
            "has_bias": len(detected_biases) > 0,
            "bias_count": len(detected_biases),
            "detected_biases": detected_biases,
            "bias_score": min(100, len(detected_biases) * 20)
        }