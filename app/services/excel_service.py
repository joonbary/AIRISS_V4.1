"""Excel ë³´ê³ ì„œ ìƒì„± ì„œë¹„ìŠ¤"""

import os
import pandas as pd
from datetime import datetime
from typing import List, Dict, Any
import logging

from app.core.analyzers.framework import AIRISS_FRAMEWORK
from app.services.analysis_storage_service import storage_service

logger = logging.getLogger(__name__)


class ExcelReportService:
    """Excel ë³´ê³ ì„œ ìƒì„± ì„œë¹„ìŠ¤"""
    
    async def create_report(
        self,
        job_id: str,
        results: List[Dict[str, Any]],
        enable_ai: bool = False,
        analysis_mode: str = "hybrid",
        hybrid_stats: Dict[str, Any] = {}
    ) -> str:
        """AIRISS v4.0 Excel ë³´ê³ ì„œ ìƒì„± (DBì—ì„œ ì§ì ‘ ê²°ê³¼ ì¡°íšŒ)"""
        try:
            # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs('results', exist_ok=True)

            # ğŸ”¥ DBì—ì„œ ìµœì‹  ê²°ê³¼ ì§ì ‘ ì¡°íšŒ (results íŒŒë¼ë¯¸í„° ë¬´ì‹œ)
            db_results = storage_service.get_analysis_results(file_id=job_id)
            if db_results:
                df_results = pd.DataFrame(db_results)
            else:
                df_results = pd.DataFrame(results)

            # AI í”¼ë“œë°± ì»¬ëŸ¼ ëˆ„ë½ ë°©ì§€: í•­ìƒ í¬í•¨ ë° ëª…í™•í•œ ê¸°ë³¸ê°’
            ai_feedback_columns = [
                ("ai_strengths", "N/A"),
                ("ai_weaknesses", "N/A"),
                ("ai_feedback", "N/A"),
                ("ai_recommendations", [])
            ]
            for col, default in ai_feedback_columns:
                if col not in df_results.columns:
                    df_results[col] = default
                else:
                    # ê²°ì¸¡ê°’/None/ë¹ˆê°’ ì²˜ë¦¬
                    if col == "ai_recommendations":
                        df_results[col] = df_results[col].apply(lambda x: x if isinstance(x, list) and x else [])
                    else:
                        df_results[col] = df_results[col].fillna(default).replace('', default)
            # ì»¬ëŸ¼ ìˆœì„œ ë³´ì¥ (ì£¼ìš” ì»¬ëŸ¼ + AI í”¼ë“œë°±)
            preferred_order = [
                "uid", "filename", "opinion", "hybrid_score", "text_score", "quantitative_score", "ok_grade", "grade_description", "confidence", "dimension_scores",
                "ai_strengths", "ai_weaknesses", "ai_feedback", "ai_recommendations", "analysis_mode", "version", "created_at", "updated_at"
            ]
            ordered_cols = [col for col in preferred_order if col in df_results.columns] + [col for col in df_results.columns if col not in preferred_order]
            df_results = df_results[ordered_cols]

            # OKë“±ê¸‰ë³„ ë¶„í¬ ê³„ì‚°
            grade_distribution = df_results["ok_grade"].value_counts() if "ok_grade" in df_results.columns else []

            # í†µê³„ ìš”ì•½ ìƒì„±
            summary_stats = self._create_summary_stats(df_results, df_results.to_dict('records'), analysis_mode, hybrid_stats, grade_distribution)
            df_summary = pd.DataFrame(summary_stats)

            # íŒŒì¼ëª… ìƒì„±
            ai_suffix = "_AIì™„ì „ë¶„ì„" if enable_ai else "_í•˜ì´ë¸Œë¦¬ë“œë¶„ì„"
            mode_suffix = f"_{analysis_mode}ëª¨ë“œ"
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_path = f'results/OKê¸ˆìœµê·¸ë£¹_AIRISS_v4.0{mode_suffix}{ai_suffix}_{timestamp}.xlsx'

            # Excel íŒŒì¼ ìƒì„±
            with pd.ExcelWriter(result_path, engine='openpyxl') as writer:
                # ë©”ì¸ ê²°ê³¼ ì‹œíŠ¸
                df_results.to_excel(writer, index=False, sheet_name='AIRISS_v4.0_ë¶„ì„ê²°ê³¼')
                # í†µê³„ ìš”ì•½ ì‹œíŠ¸
                df_summary.to_excel(writer, index=False, sheet_name='v4.0_í†µê³„ìš”ì•½')
                # 8ëŒ€ ì˜ì—­ë³„ ìƒì„¸ ì‹œíŠ¸
                dimension_analysis = self._create_dimension_analysis(df_results)
                df_dimensions = pd.DataFrame(dimension_analysis)
                df_dimensions.to_excel(writer, index=False, sheet_name='ì˜ì—­ë³„_ë¶„ì„')
                # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ìƒì„¸ ì‹œíŠ¸
                hybrid_analysis = self._create_hybrid_analysis(df_results)
                df_hybrid = pd.DataFrame(hybrid_analysis)
                df_hybrid.to_excel(writer, index=False, sheet_name='í•˜ì´ë¸Œë¦¬ë“œ_ë¹„êµë¶„ì„')

            logger.info(f"AIRISS v4.0 Excel ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {result_path}")
            return result_path
        except Exception as e:
            logger.error(f"Excel ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
            raise
    
    def _create_summary_stats(
        self,
        df_results: pd.DataFrame,
        results: List[Dict],
        analysis_mode: str,
        hybrid_stats: Dict,
        grade_distribution: pd.Series
    ) -> List[Dict[str, Any]]:
        """í†µê³„ ìš”ì•½ ë°ì´í„° ìƒì„±"""
        summary_stats = []
        summary_stats.append({
            "í•­ëª©": "AIRISS ë²„ì „",
            "ê°’": "v4.0 ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤",
            "ì„¤ëª…": "í…ìŠ¤íŠ¸ + ì •ëŸ‰ë°ì´í„° í†µí•©ë¶„ì„ API ì„œë²„"
        })
        summary_stats.append({
            "í•­ëª©": "ì „ì²´ ë¶„ì„ ê±´ìˆ˜",
            "ê°’": len(results),
            "ì„¤ëª…": "ì´ ë¶„ì„ëœ ì§ì› ìˆ˜"
        })
        summary_stats.append({
            "í•­ëª©": "ë¶„ì„ ëª¨ë“œ",
            "ê°’": analysis_mode,
            "ì„¤ëª…": "ì ìš©ëœ ë¶„ì„ ë°©ì‹"
        })
        # ì•ˆì „í•˜ê²Œ í‰ê·  í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
        if "hybrid_score" in df_results.columns and not df_results.empty:
            avg_hybrid = round(df_results["hybrid_score"].mean(), 1)
        else:
            avg_hybrid = 0
        summary_stats.append({
            "í•­ëª©": "í‰ê·  í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜",
            "ê°’": avg_hybrid,
            "ì„¤ëª…": "ì „ì²´ ì§ì› í‰ê·  í†µí•© ì ìˆ˜"
        })
        if "quant_data_count" in df_results.columns and not df_results.empty:
            avg_quant_data = round(df_results["quant_data_count"].mean(), 1)
            summary_stats.append({
                "í•­ëª©": "í‰ê·  ì •ëŸ‰ë°ì´í„° ìˆ˜",
                "ê°’": avg_quant_data,
                "ì„¤ëª…": "ê°œì¸ë‹¹ í‰ê·  ì •ëŸ‰ë°ì´í„° ê°œìˆ˜"
            })
        if hybrid_stats.get("quantitative_usage_rate"):
            summary_stats.append({
                "í•­ëª©": "ì •ëŸ‰ë°ì´í„° í™œìš©ë¥ ",
                "ê°’": f"{hybrid_stats['quantitative_usage_rate']}%",
                "ì„¤ëª…": "ì •ëŸ‰ë°ì´í„°ê°€ í¬í•¨ëœ ë¶„ì„ ë¹„ìœ¨"
            })
        # OKë“±ê¸‰ë³„ ë¶„í¬
        if isinstance(grade_distribution, pd.Series) and not df_results.empty:
            for grade, count in grade_distribution.items():
                percentage = (count / len(results)) * 100 if len(results) > 0 else 0
                summary_stats.append({
                    "í•­ëª©": f"{grade} ë“±ê¸‰",
                    "ê°’": f"{count}ëª… ({percentage:.1f}%)",
                    "ì„¤ëª…": f"{grade} ë“±ê¸‰ ì§ì› ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ ê¸°ì¤€)"
                })
        return summary_stats
    
    def _create_dimension_analysis(self, df_results: pd.DataFrame) -> List[Dict[str, Any]]:
        """8ëŒ€ ì˜ì—­ë³„ ë¶„ì„ ë°ì´í„° ìƒì„±"""
        dimension_analysis = []
        
        # dimension_scoresê°€ ë¬¸ìì—´ë¡œ ì €ì¥ë˜ì–´ ìˆìœ¼ë¯€ë¡œ íŒŒì‹± í•„ìš”
        for dimension in AIRISS_FRAMEWORK.keys():
            dimension_info = AIRISS_FRAMEWORK[dimension]
            
            # ê° í–‰ì˜ dimension_scoresì—ì„œ í•´ë‹¹ ì°¨ì› ì ìˆ˜ ì¶”ì¶œ
            scores = []
            for idx, row in df_results.iterrows():
                try:
                    dim_scores = eval(row.get("dimension_scores", "{}"))
                    score = dim_scores.get(dimension, 50)
                    scores.append(score)
                except:
                    scores.append(50)
            
            scores = pd.Series(scores)
            
            dimension_analysis.append({
                "ì˜ì—­": dimension,
                "ì•„ì´ì½˜": dimension_info['icon'],
                "ê°€ì¤‘ì¹˜": f"{dimension_info['weight']*100}%",
                "ì„¤ëª…": dimension_info['description'],
                "í‰ê· ì ìˆ˜": round(scores.mean(), 1),
                "ìµœê³ ì ìˆ˜": round(scores.max(), 1),
                "ìµœì €ì ìˆ˜": round(scores.min(), 1),
                "í‘œì¤€í¸ì°¨": round(scores.std(), 1),
                "ìš°ìˆ˜ììˆ˜": len(scores[scores >= 80]),
                "ê°œì„ í•„ìš”ììˆ˜": len(scores[scores < 60])
            })
        
        return dimension_analysis
    
    def _create_hybrid_analysis(self, df_results: pd.DataFrame) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ë¹„êµ ë°ì´í„° ìƒì„±"""
        hybrid_analysis = []
        
        if "hybrid_score" in df_results.columns and "text_total_score" in df_results.columns:
            hybrid_scores = df_results["hybrid_score"]
            text_scores = df_results["text_total_score"]
            quant_scores = df_results["quant_total_score"] if "quant_total_score" in df_results.columns else pd.Series([50] * len(df_results))
            
            hybrid_analysis.append({
                "ë¶„ì„ìœ í˜•": "í•˜ì´ë¸Œë¦¬ë“œ í†µí•©",
                "í‰ê· ì ìˆ˜": round(hybrid_scores.mean(), 1),
                "ìµœê³ ì ìˆ˜": round(hybrid_scores.max(), 1),
                "ìµœì €ì ìˆ˜": round(hybrid_scores.min(), 1),
                "í‘œì¤€í¸ì°¨": round(hybrid_scores.std(), 1),
                "ì‹ ë¢°ë„": "ë†’ìŒ (ë‹¤ì¤‘ì†ŒìŠ¤)"
            })
            
            hybrid_analysis.append({
                "ë¶„ì„ìœ í˜•": "í…ìŠ¤íŠ¸ ë¶„ì„",
                "í‰ê· ì ìˆ˜": round(text_scores.mean(), 1),
                "ìµœê³ ì ìˆ˜": round(text_scores.max(), 1),
                "ìµœì €ì ìˆ˜": round(text_scores.min(), 1),
                "í‘œì¤€í¸ì°¨": round(text_scores.std(), 1),
                "ì‹ ë¢°ë„": "ì¤‘ê°„ (í‚¤ì›Œë“œ ê¸°ë°˜)"
            })
            
            hybrid_analysis.append({
                "ë¶„ì„ìœ í˜•": "ì •ëŸ‰ ë¶„ì„",
                "í‰ê· ì ìˆ˜": round(quant_scores.mean(), 1),
                "ìµœê³ ì ìˆ˜": round(quant_scores.max(), 1),
                "ìµœì €ì ìˆ˜": round(quant_scores.min(), 1),
                "í‘œì¤€í¸ì°¨": round(quant_scores.std(), 1),
                "ì‹ ë¢°ë„": "ë†’ìŒ (ê°ê´€ì  ë°ì´í„°)"
            })
        
        return hybrid_analysis