# app/services/hybrid_analyzer.py
"""
AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ê¸° - Python 3.13 ì™„ì „ í˜¸í™˜ ë²„ì „
í…ìŠ¤íŠ¸ + ì •ëŸ‰ ë°ì´í„° í†µí•© ë¶„ì„ + í¸í–¥ íƒì§€ + ì¡°ê±´ë¶€ ì˜êµ¬ ì €ì¥
"""

import pandas as pd
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime
import uuid
import numpy as np
import os

from app.services.text_analyzer import AIRISSTextAnalyzer
from app.services.quantitative_analyzer import QuantitativeAnalyzer

logger = logging.getLogger(__name__)

def safe_convert_numpy_types(value):
    """numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
    if isinstance(value, np.integer):
        return int(value)
    elif isinstance(value, np.floating):
        return float(value)
    elif isinstance(value, np.ndarray):
        return value.tolist()
    elif isinstance(value, dict):
        return {k: safe_convert_numpy_types(v) for k, v in value.items()}
    elif isinstance(value, list):
        return [safe_convert_numpy_types(item) for item in value]
    else:
        return value

class AIRISSHybridAnalyzer:
    """í…ìŠ¤íŠ¸ + ì •ëŸ‰ í†µí•© ë¶„ì„ê¸° with í¸í–¥ íƒì§€ + ì•ˆì „í•œ ì˜êµ¬ ì €ì¥"""
    
    def __init__(self):
        self.text_analyzer = AIRISSTextAnalyzer()
        self.quantitative_analyzer = QuantitativeAnalyzer()
        
        # í¸í–¥ íƒì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.bias_detector = None
        try:
            from app.services.bias_detection import BiasDetector
            self.bias_detector = BiasDetector()
            logger.info("âœ… í¸í–¥ íƒì§€ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
        except ImportError:
            logger.warning("âš ï¸ í¸í–¥ íƒì§€ ëª¨ë“ˆ ì—†ìŒ - ê¸°ë³¸ ë¶„ì„ë§Œ ìˆ˜í–‰")
        except Exception as e:
            logger.warning(f"âš ï¸ í¸í–¥ íƒì§€ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ğŸ”¥ Python 3.13 í˜¸í™˜: ì™„ì „í•œ ì¡°ê±´ë¶€ ì €ì¥ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.storage_service = None
        self.storage_available = False
        
        try:
            # ë‹¨ê³„ë³„ ì•ˆì „í•œ import
            logger.info("ğŸ”„ ì €ì¥ ì„œë¹„ìŠ¤ ë¡œë“œ ì‹œë„...")
            from app.services.analysis_storage_service import storage_service
            
            # ì„œë¹„ìŠ¤ ê°€ìš©ì„± í™•ì¸
            if hasattr(storage_service, 'is_available') and storage_service.is_available():
                self.storage_service = storage_service
                self.storage_available = True
                logger.info("âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì„œë¹„ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ì €ì¥ ì„œë¹„ìŠ¤ê°€ ë¹„í™œì„±í™” ìƒíƒœ")
                
        except ImportError as e:
            logger.warning(f"âš ï¸ ì €ì¥ ì„œë¹„ìŠ¤ ëª¨ë“ˆ ì—†ìŒ: {e}")
        except Exception as e:
            logger.warning(f"âš ï¸ ì €ì¥ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨ (Python 3.13 í˜¸í™˜ì„±): {e}")
            logger.info("ğŸ“ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë¶„ì„ë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤")
        
        # í†µí•© ê°€ì¤‘ì¹˜
        self.hybrid_weights = {
            'text_analysis': 0.6,
            'quantitative_analysis': 0.4
        }
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥ (í¸í–¥ íƒì§€ìš©) - í•­ìƒ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
        self.analysis_history = []
        
        # ì´ˆê¸°í™” ìƒíƒœ ë¡œê¹…
        logger.info(f"âœ… AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   ğŸ“Š í¸í–¥ íƒì§€: {'í™œì„±í™”' if self.bias_detector else 'ë¹„í™œì„±í™”'}")
        logger.info(f"   ğŸ’¾ ì˜êµ¬ ì €ì¥: {'í™œì„±í™”' if self.storage_available else 'ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ë§Œ)'}")
    
    async def comprehensive_analysis(self, 
                             uid: str, 
                             opinion: str, 
                             row_data: pd.Series,
                             save_to_storage: bool = True,
                             file_id: Optional[str] = None,
                             filename: Optional[str] = None,
                             enable_ai: bool = False,
                             openai_api_key: Optional[str] = None,
                             openai_model: str = "gpt-3.5-turbo",
                             max_tokens: int = 1200) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„: í…ìŠ¤íŠ¸ + ì •ëŸ‰ + í¸í–¥ ì²´í¬ + ì•ˆì „í•œ ì˜êµ¬ ì €ì¥"""
        
        # 1. í…ìŠ¤íŠ¸ ë¶„ì„
        text_results = {}
        for dimension in self.text_analyzer.framework.keys():
            text_results[dimension] = self.text_analyzer.analyze_text(opinion, dimension)
        
        text_overall = self.text_analyzer.calculate_overall_score(
            {dim: result["score"] for dim, result in text_results.items()}
        )
        
        # 2. ì •ëŸ‰ ë¶„ì„
        quant_data = self.quantitative_analyzer.extract_quantitative_data(row_data)
        quant_results = self.quantitative_analyzer.calculate_quantitative_score(quant_data)
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
        text_weight = self.hybrid_weights['text_analysis']
        quant_weight = self.hybrid_weights['quantitative_analysis']
        
        # ë°ì´í„° í’ˆì§ˆì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
        if quant_results["data_quality"] == "ì—†ìŒ":
            text_weight = 0.8
            quant_weight = 0.2
        elif quant_results["data_quality"] == "ë‚®ìŒ":
            text_weight = 0.7
            quant_weight = 0.3
        elif quant_results["data_quality"] == "ë†’ìŒ":
            text_weight = 0.5
            quant_weight = 0.5
        
        hybrid_score = (
            text_overall["overall_score"] * text_weight + 
            quant_results["quantitative_score"] * quant_weight
        )
        
        # 4. í†µí•© ì‹ ë¢°ë„
        hybrid_confidence = (
            text_overall.get("confidence", 70) * text_weight + 
            quant_results["confidence"] * quant_weight
        )
        
        # 5. í•˜ì´ë¸Œë¦¬ë“œ ë“±ê¸‰
        hybrid_grade_info = self._calculate_hybrid_grade(hybrid_score)
        
        # 6. ì„¤ëª…ê°€ëŠ¥ì„± ì •ë³´ ì¶”ê°€
        explainability_info = self._generate_explainability(
            text_results, quant_results, text_weight, quant_weight, hybrid_score
        )
        
        # 7. ë¶„ì„ ê²°ê³¼ ì €ì¥ (í¸í–¥ íƒì§€ìš©)
        if hasattr(row_data, 'to_dict'):
            analysis_record = {
                'uid': uid,
                'hybrid_score': hybrid_score,
                'timestamp': datetime.now()
            }
            # ë³´í˜¸ ì†ì„± ì¶”ê°€ (ìˆëŠ” ê²½ìš°) - pandas Seriesë¥¼ Python ë„¤ì´í‹°ë¸Œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
            for attr in ['ì„±ë³„', 'ì—°ë ¹ëŒ€', 'ë¶€ì„œ', 'ì§ê¸‰']:
                if attr in row_data:
                    value = row_data[attr]
                    # pandas Seriesë‚˜ numpy íƒ€ì…ì„ Python ë„¤ì´í‹°ë¸Œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                    if hasattr(value, 'item'):  # numpy scalar
                        analysis_record[attr] = value.item()
                    elif hasattr(value, 'tolist'):  # pandas Series/array
                        analysis_record[attr] = value.tolist() if hasattr(value, '__len__') and len(value) > 1 else value.iloc[0] if hasattr(value, 'iloc') else str(value)
                    else:
                        analysis_record[attr] = value
            self.analysis_history.append(analysis_record)
        
        # 8. AI í”¼ë“œë°± ìƒì„± (ë¹„ë™ê¸° ì§€ì›)
        ai_feedback_result = {
            "ai_strengths": "",
            "ai_weaknesses": "",
            "ai_feedback": "",
            "ai_recommendations": [],
            "error": None
        }
        
        # OpenAI API í˜¸ì¶œ ì¤€ë¹„
        if enable_ai:
            logger.info("ğŸ¤– AI ë¶„ì„ í™œì„±í™”: OpenAI API í˜¸ì¶œ ì¤€ë¹„")
            logger.info("   AI ë¶„ì„ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        # API í‚¤ í™•ì¸ ë° ê²€ì¦
        if enable_ai:
            from app.utils.validate_api_key import is_valid_api_key, get_valid_api_key
            
            # ì „ë‹¬ëœ API í‚¤ ê²€ì¦
            if openai_api_key and not is_valid_api_key(openai_api_key):
                logger.warning(f"ì „ë‹¬ëœ API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ: {openai_api_key[:10] if openai_api_key else 'None'}...")
                openai_api_key = None
            
            # API í‚¤ê°€ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            if not openai_api_key:
                openai_api_key = get_valid_api_key()
            
            if openai_api_key:
                try:
                    logger.info(f"AI í”¼ë“œë°± ìƒì„± ì‹œì‘ - UID: {uid}, API í‚¤: {openai_api_key[:10]}...")
                    ai_feedback_result = await self.text_analyzer.generate_ai_feedback(
                        uid=uid,
                        opinion=opinion,
                        api_key=openai_api_key,
                        model=openai_model,
                        max_tokens=max_tokens
                    )
                    logger.info(f"AI í”¼ë“œë°± ìƒì„± ì™„ë£Œ - UID: {uid}")
                    logger.debug(f"AI í”¼ë“œë°± ë‚´ìš©: {ai_feedback_result}")
                    
                    # AI ë¶„ì„ì´ ì‹¤íŒ¨í–ˆëŠ”ì§€ í™•ì¸ (í´ë°± ì‘ë‹µì¸ ê²½ìš°)
                    if ai_feedback_result.get("error"):
                        error_msg = ai_feedback_result["error"]
                        logger.warning(f"AI ë¶„ì„ í´ë°± ì‘ë‹µ ì‚¬ìš©: {error_msg}")
                        # ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•  ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€
                        if "api" in error_msg.lower() and "key" in error_msg.lower():
                            ai_feedback_result["user_error"] = "OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                        elif "timeout" in error_msg.lower():
                            ai_feedback_result["user_error"] = "OpenAI API ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        elif "connection" in error_msg.lower() or "network" in error_msg.lower():
                            ai_feedback_result["user_error"] = "OpenAI API ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                        elif "rate" in error_msg.lower() or "limit" in error_msg.lower():
                            ai_feedback_result["user_error"] = "OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        else:
                            ai_feedback_result["user_error"] = f"AI ë¶„ì„ ì‹¤íŒ¨: {error_msg}"
                            
                except Exception as e:
                    error_str = str(e)
                    logger.error(f"AI í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {error_str}")
                    ai_feedback_result["error"] = error_str
                    
                    # ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€
                    if "Invalid" in error_str or "API" in error_str:
                        ai_feedback_result["user_error"] = "OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                    else:
                        ai_feedback_result["user_error"] = f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_str}"
                    
                    # AI ë¶„ì„ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ë¶„ì„ì€ ê³„ì† ì§„í–‰
                    logger.info("AI ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            else:
                logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                ai_feedback_result["error"] = "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
                ai_feedback_result["user_error"] = "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        # 9. ë¶„ì„ ê²°ê³¼ êµ¬ì„± (numpy íƒ€ì… ì•ˆì „ ë³€í™˜)
        analysis_result = {
            "text_analysis": {
                "overall_score": safe_convert_numpy_types(text_overall["overall_score"]),
                "grade": text_overall["grade"],
                "dimension_scores": {dim: safe_convert_numpy_types(result["score"]) for dim, result in text_results.items()},
                "dimension_details": safe_convert_numpy_types(text_results)
            },
            "quantitative_analysis": safe_convert_numpy_types(quant_results),
            "hybrid_analysis": {
                "overall_score": safe_convert_numpy_types(round(hybrid_score, 1)),
                "grade": hybrid_grade_info["grade"],
                "grade_description": hybrid_grade_info["grade_description"],
                "percentile": hybrid_grade_info["percentile"],
                "confidence": safe_convert_numpy_types(round(hybrid_confidence, 1)),
                "analysis_composition": {
                    "text_weight": safe_convert_numpy_types(round(text_weight * 100, 1)),
                    "quantitative_weight": safe_convert_numpy_types(round(quant_weight * 100, 1))
                }
            },
            "explainability": safe_convert_numpy_types(explainability_info),
            "ai_feedback": ai_feedback_result,  # AI í”¼ë“œë°± ê²°ê³¼ ì¶”ê°€
            "analysis_metadata": {
                "uid": uid,
                "analysis_version": "AIRISS v4.0 - Hybrid Enhanced (Python 3.13 Compatible)",
                "data_sources": {
                    "text_available": bool(opinion and opinion.strip()),
                    "quantitative_available": bool(quant_data),
                    "quantitative_data_quality": quant_results["data_quality"]
                },
                "bias_detection_available": self.bias_detector is not None,
                "storage_available": self.storage_available
            }
        }
        
        # 9. ì˜êµ¬ ì €ì¥ (ì¡°ê±´ë¶€ ì•ˆì „í•œ ì €ì¥)
        if save_to_storage:
            storage_result = self._safe_save_to_storage(
                uid, file_id, filename, opinion, hybrid_score, 
                text_overall, quant_results, hybrid_grade_info, hybrid_confidence, text_results,
                ai_feedback_result
            )
            analysis_result["storage_info"] = storage_result
        
        return analysis_result
    
    def _safe_save_to_storage(self, uid, file_id, filename, opinion, hybrid_score,
                            text_overall, quant_results, hybrid_grade_info, hybrid_confidence, text_results,
                            ai_feedback_result=None):
        """ì•ˆì „í•œ ì €ì¥ ì²˜ë¦¬ (Python 3.13 í˜¸í™˜)"""
        
        if not self.storage_available or not self.storage_service:
            return {
                "storage_enabled": False,
                "message": "ì €ì¥ ì„œë¹„ìŠ¤ ë¹„í™œì„±í™” - ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ë¨",
                "reason": "python_313_compatibility"
            }
        
        try:
            storage_data = {
                "uid": uid,
                "file_id": file_id or str(uuid.uuid4()),
                "filename": filename or "unknown",
                "opinion": opinion,
                "hybrid_score": safe_convert_numpy_types(hybrid_score),
                "text_score": safe_convert_numpy_types(text_overall["overall_score"]),
                "quantitative_score": safe_convert_numpy_types(quant_results["quantitative_score"]),
                "ok_grade": hybrid_grade_info["grade"],
                "grade_description": hybrid_grade_info["grade_description"],
                "confidence": safe_convert_numpy_types(hybrid_confidence),
                "dimension_scores": {dim: safe_convert_numpy_types(result["score"]) for dim, result in text_results.items()},
                "analysis_mode": "hybrid",
                "version": "4.0"
            }
            # AI í”¼ë“œë°± ì»¬ëŸ¼ ì¶”ê°€
            if ai_feedback_result:
                storage_data.update({
                    "ai_strengths": ai_feedback_result.get("ai_strengths", ""),
                    "ai_weaknesses": ai_feedback_result.get("ai_weaknesses", ""),
                    "ai_feedback": ai_feedback_result.get("ai_feedback", ""),
                    "ai_recommendations": ai_feedback_result.get("ai_recommendations", []),
                    "ai_error": ai_feedback_result.get("error", None)
                })
            
            analysis_id = self.storage_service.save_analysis_result(storage_data)
            
            return {
                "analysis_id": analysis_id,
                "saved_at": datetime.now().isoformat(),
                "storage_enabled": True,
                "storage_mode": "persistent"
            }
            
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            # ë©”ëª¨ë¦¬ ì €ì¥ì†Œì—ë¼ë„ ì €ì¥
            memory_id = f"mem_{uid}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            return {
                "analysis_id": memory_id,
                "error": str(e),
                "storage_enabled": False,
                "storage_mode": "memory_fallback",
                "message": "ì˜êµ¬ ì €ì¥ ì‹¤íŒ¨ - ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ë¨"
            }
    
    def save_analysis_job(self, job_info: Dict[str, Any]) -> Optional[str]:
        """ë¶„ì„ ì‘ì—… ì •ë³´ ì €ì¥ (ì•ˆì „í•œ ì²˜ë¦¬)"""
        if not self.storage_available or not self.storage_service:
            logger.info("ì €ì¥ ì„œë¹„ìŠ¤ ë¹„í™œì„±í™” - ì‘ì—… ì •ë³´ ì €ì¥ ê±´ë„ˆëœ€")
            return None
        
        try:
            job_id = self.storage_service.save_analysis_job(job_info)
            logger.info(f"âœ… ë¶„ì„ ì‘ì—… ì •ë³´ ì €ì¥ ì™„ë£Œ: {job_id}")
            return job_id
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ì‘ì—… ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def get_stored_analysis_results(self, 
                                  file_id: Optional[str] = None,
                                  uid: Optional[str] = None,
                                  limit: int = 100) -> List[Dict[str, Any]]:
        """ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ì•ˆì „í•œ ì²˜ë¦¬)"""
        if not self.storage_available or not self.storage_service:
            logger.info("ì €ì¥ ì„œë¹„ìŠ¤ ë¹„í™œì„±í™” - ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return []
        
        try:
            results = self.storage_service.get_analysis_results(
                file_id=file_id,
                uid=uid,
                limit=limit
            )
            return results
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_analysis_statistics(self, days: int = 30) -> Dict[str, Any]:
        """ë¶„ì„ í†µê³„ ì¡°íšŒ (ì•ˆì „í•œ ì²˜ë¦¬)"""
        if not self.storage_available or not self.storage_service:
            return {
                "message": "ì €ì¥ ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”",
                "memory_analysis_count": len(self.analysis_history),
                "storage_mode": "memory_only"
            }
        
        try:
            stats = self.storage_service.get_analysis_statistics(days=days)
            return stats
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "memory_analysis_count": len(self.analysis_history),
                "storage_mode": "error_fallback"
            }
    
    def _calculate_hybrid_grade(self, score: float) -> Dict[str, str]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¥¼ 7ë‹¨ê³„ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜ (S, A+, A, B+, B, C, D)"""
        if score >= 95:
            return {
                "grade": "S",
                "grade_description": "íƒì›”í•¨ (Superb) - ì „ì‚¬ TOP 1%",
                "percentile": "ìƒìœ„ 1%"
            }
        elif score >= 90:
            return {
                "grade": "A+",
                "grade_description": "ë§¤ìš° ìš°ìˆ˜ (Excellent) - ì „ì‚¬ TOP 5%",
                "percentile": "ìƒìœ„ 5%"
            }
        elif score >= 80:
            return {
                "grade": "A",
                "grade_description": "ìš°ìˆ˜ (Outstanding) - ì „ì‚¬ TOP 15%",
                "percentile": "ìƒìœ„ 15%"
            }
        elif score >= 70:
            return {
                "grade": "B+",
                "grade_description": "ì–‘í˜¸ (Good) - ì „ì‚¬ TOP 30%",
                "percentile": "ìƒìœ„ 30%"
            }
        elif score >= 60:
            return {
                "grade": "B",
                "grade_description": "ë³´í†µ (Average) - ì „ì‚¬ TOP 50%",
                "percentile": "ìƒìœ„ 50%"
            }
        elif score >= 50:
            return {
                "grade": "C",
                "grade_description": "ê°œì„  í•„ìš” (Needs Improvement) - ì „ì‚¬ TOP 70%",
                "percentile": "ìƒìœ„ 70%"
            }
        else:
            return {
                "grade": "D",
                "grade_description": "ì§‘ì¤‘ ê´€ë¦¬ í•„ìš” (Requires Attention) - í•˜ìœ„ 30%",
                "percentile": "í•˜ìœ„ 30%"
            }
    
    def _generate_explainability(self, 
                               text_results: Dict,
                               quant_results: Dict,
                               text_weight: float,
                               quant_weight: float,
                               hybrid_score: float) -> Dict[str, Any]:
        """ì ìˆ˜ ì‚°ì¶œ ê·¼ê±° ì„¤ëª… ìƒì„±"""
        
        # ì£¼ìš” ê¸ì •/ë¶€ì • ìš”ì¸ ì¶”ì¶œ
        positive_factors = []
        negative_factors = []
        
        # í…ìŠ¤íŠ¸ ë¶„ì„ ìš”ì¸
        for dimension, result in text_results.items():
            if result['score'] >= 80:
                positive_factors.append({
                    'factor': f"{dimension}",
                    'score': result['score'],
                    'impact': result['score'] * self.text_analyzer.framework[dimension]['weight'] * text_weight,
                    'evidence': result.get('signals', {}).get('positive_words', [])[:3]
                })
            elif result['score'] < 60:
                negative_factors.append({
                    'factor': f"{dimension}",
                    'score': result['score'],
                    'impact': (100 - result['score']) * self.text_analyzer.framework[dimension]['weight'] * text_weight,
                    'evidence': result.get('signals', {}).get('negative_words', [])[:3]
                })
        
        # ì •ëŸ‰ ë¶„ì„ ìš”ì¸
        if quant_results['quantitative_score'] >= 80:
            positive_factors.append({
                'factor': "ì •ëŸ‰ì  ì„±ê³¼",
                'score': quant_results['quantitative_score'],
                'impact': quant_results['quantitative_score'] * quant_weight,
                'evidence': ["KPI ë‹¬ì„±", "ì„±ê³¼ ìš°ìˆ˜"]
            })
        elif quant_results['quantitative_score'] < 60:
            negative_factors.append({
                'factor': "ì •ëŸ‰ì  ì„±ê³¼",
                'score': quant_results['quantitative_score'],
                'impact': (100 - quant_results['quantitative_score']) * quant_weight,
                'evidence': ["KPI ë¯¸ë‹¬", "ì„±ê³¼ ë¶€ì§„"]
            })
        
        # ìƒìœ„ 3ê°œ ìš”ì¸ ì •ë ¬
        positive_factors.sort(key=lambda x: x['impact'], reverse=True)
        negative_factors.sort(key=lambda x: x['impact'], reverse=True)
        
        return {
            "score_breakdown": {
                "text_contribution": round(text_results.get('ì—…ë¬´ì„±ê³¼', {}).get('score', 50) * text_weight, 1),
                "quantitative_contribution": round(quant_results['quantitative_score'] * quant_weight, 1),
                "final_score": round(hybrid_score, 1)
            },
            "key_positive_factors": positive_factors[:3],
            "key_negative_factors": negative_factors[:3],
            "improvement_suggestions": self._generate_improvement_suggestions(negative_factors),
            "confidence_explanation": self._explain_confidence(text_results, quant_results)
        }
    
    def _generate_improvement_suggestions(self, negative_factors: List[Dict]) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        for factor in negative_factors[:3]:
            if factor['factor'] == "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜":
                suggestions.append("ğŸ’¡ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤í‚¬ í–¥ìƒ êµìœ¡ ì°¸ì—¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
            elif factor['factor'] == "ë¦¬ë”ì‹­í˜‘ì—…":
                suggestions.append("ğŸ’¡ íŒ€ì›Œí¬ ë° í˜‘ì—… ì—­ëŸ‰ ê°•í™” í”„ë¡œê·¸ë¨ ì°¸ì—¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            elif factor['factor'] == "ì „ë¬¸ì„±í•™ìŠµ":
                suggestions.append("ğŸ’¡ ì§ë¬´ ê´€ë ¨ ì „ë¬¸ êµìœ¡ ë° ìê²©ì¦ ì·¨ë“ì„ ì¶”ì²œí•©ë‹ˆë‹¤.")
            elif factor['factor'] == "ì—…ë¬´ì„±ê³¼":
                suggestions.append("ğŸ’¡ ëª©í‘œ ì„¤ì • ë° ì‹œê°„ ê´€ë¦¬ ê¸°ë²• í•™ìŠµì´ ë„ì›€ë  ê²ƒì…ë‹ˆë‹¤.")
            elif factor['factor'] == "ì •ëŸ‰ì  ì„±ê³¼":
                suggestions.append("ğŸ’¡ KPI ë‹¬ì„±ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return suggestions[:3]  # ìµœëŒ€ 3ê°œ ì œì•ˆ
    
    def _explain_confidence(self, text_results: Dict, quant_results: Dict) -> str:
        """ì‹ ë¢°ë„ ì„¤ëª…"""
        avg_text_confidence = sum(r.get('confidence', 0) for r in text_results.values()) / len(text_results)
        quant_confidence = quant_results.get('confidence', 0)
        
        if avg_text_confidence >= 80 and quant_confidence >= 80:
            return "ë†’ì€ ì‹ ë¢°ë„: ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ ì •ë³´ì™€ ì •ëŸ‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤."
        elif avg_text_confidence >= 60 or quant_confidence >= 60:
            return "ì¤‘ê°„ ì‹ ë¢°ë„: ì¼ë¶€ ë°ì´í„°ê°€ ì œí•œì ì´ì§€ë§Œ ì˜ë¯¸ìˆëŠ” ë¶„ì„ì´ ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤."
        else:
            return "ë‚®ì€ ì‹ ë¢°ë„: ì œí•œëœ ì •ë³´ë¡œ ì¸í•´ ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
    
    def detect_bias_in_batch(self, analysis_results_df: pd.DataFrame) -> Dict[str, Any]:
        """ë°°ì¹˜ ë¶„ì„ ê²°ê³¼ì˜ í¸í–¥ íƒì§€ (ì•ˆì „í•œ ì²˜ë¦¬)"""
        if not self.bias_detector:
            return {
                "error": "í¸í–¥ íƒì§€ ì‹œìŠ¤í…œì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "recommendation": "bias_detection ëª¨ë“ˆì„ ì„¤ì¹˜í•˜ì„¸ìš”."
            }
        
        try:
            bias_report = self.bias_detector.detect_bias(analysis_results_df)
            return bias_report
        except Exception as e:
            logger.error(f"í¸í–¥ íƒì§€ ì˜¤ë¥˜: {e}")
            return {
                "error": f"í¸í–¥ íƒì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "recommendation": "ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”."
            }
    
    def get_fairness_metrics(self) -> Dict[str, Any]:
        """í˜„ì¬ê¹Œì§€ ë¶„ì„ëœ ë°ì´í„°ì˜ ê³µì •ì„± ë©”íŠ¸ë¦­"""
        if not self.analysis_history:
            return {
                "status": "no_data",
                "message": "ì•„ì§ ë¶„ì„ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            }
        
        df = pd.DataFrame(self.analysis_history)
        
        metrics = {
            "total_analyzed": len(df),
            "average_score": round(df['hybrid_score'].mean(), 1),
            "score_std": round(df['hybrid_score'].std(), 1),
            "score_distribution": {
                "min": round(df['hybrid_score'].min(), 1),
                "25%": round(df['hybrid_score'].quantile(0.25), 1),
                "50%": round(df['hybrid_score'].quantile(0.50), 1),
                "75%": round(df['hybrid_score'].quantile(0.75), 1),
                "max": round(df['hybrid_score'].max(), 1)
            },
            "storage_info": {
                "storage_available": self.storage_available,
                "memory_records": len(self.analysis_history)
            }
        }
        
        # ë³´í˜¸ ì†ì„±ë³„ í‰ê·  ì ìˆ˜
        for attr in ['ì„±ë³„', 'ì—°ë ¹ëŒ€', 'ë¶€ì„œ', 'ì§ê¸‰']:
            if attr in df.columns:
                metrics[f'{attr}_averages'] = df.groupby(attr)['hybrid_score'].mean().to_dict()
        
        return metrics
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        return {
            "version": "AIRISS v4.0 - Python 3.13 Compatible",
            "components": {
                "text_analyzer": True,
                "quantitative_analyzer": True,
                "bias_detector": self.bias_detector is not None,
                "storage_service": self.storage_available
            },
            "analysis_count": len(self.analysis_history),
            "storage_mode": "persistent" if self.storage_available else "memory_only",
            "python_version_compatible": True
        }
